{"hash":"74df7d11e8ace9b00a8872e19e247233de37c756","data":{"realTimePost":{"description":"Expert guide to defending against Shai-Hulud 2.0. Protect your npm supply chain with proven containment, rotation, and recovery strategies. David Cohen, JFrog Security Researcher.","title":"Defending Against Shai-Hulud: Protection & Response Guide","date":"November 26, 2025","type":"realTimePost","tag":"Real Time Post","img":"/img/RealTimePostImage/post/shai-hulud-remediation/shai-hulud-kicked-by-frog.png","path":"/post/shai-hulud-the-second-coming-remediation-guidance/","content":"<h1 id=\"defending-against-shai-hulud-the-complete-protection-and-response-guide\"><a href=\"#defending-against-shai-hulud-the-complete-protection-and-response-guide\" aria-hidden=\"true\" tabindex=\"-1\">Defending Against Shai-Hulud: The Complete Protection and Response Guide</a></h1>\n<p>Defending your organization against the <a href=\"https://jfrog.com/blog/shai-hulud-npm-supply-chain-attack-new-compromised-packages-detected/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">\"<strong>Shai-Hulud\"</strong></a> worm and its evolved variant, <a href=\"https://research.jfrog.com/post/shai-hulud-the-second-coming/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><strong>\"Sha1-Hulud the second coming\"</strong></a>, requires immediate action and a systematic approach. This highly efficient, <strong>GitHub-weaponized exfiltration</strong> attack has compromised npm supply chains worldwide. When defending against an infected system, understanding that the malware leverages stolen tokens to create public repositories - typically identifiable by a <strong>random name</strong> and the description \"<strong>Sha1-Hulud: The Second Coming</strong>\" - is critical to protecting your credentials from exfiltration.</p>\n<p>Finding this repository means an active breach is in progress. Defending your infrastructure requires swift, systematic action following a strict order of operations to contain the leak and prevent further damage.</p>\n<hr>\n<h2 id=\"Ô∏è-quick-protection-steps\"><a href=\"#%EF%B8%8F-quick-protection-steps\" aria-hidden=\"true\" tabindex=\"-1\">üõ°Ô∏è Quick Protection Steps</a></h2>\n<p><strong>If you've discovered a Shai-Hulud compromise, take these immediate defensive actions:</strong></p>\n<ol>\n<li><strong>DO NOT DELETE</strong> the malicious GitHub repository - you need it for forensics</li>\n<li><strong>Immediately privatize</strong> the repository to stop credential exposure</li>\n<li><strong>Disable malicious workflows(GitHub Action)</strong> and remove self-hosted runners named \"SHA1HULUD\"</li>\n<li><strong>Remove infected packages</strong> from node_modules and clear npm cache</li>\n<li><strong>Rotate ALL credentials</strong> found in the exfiltration repository</li>\n<li><strong>Audit access logs</strong> for unauthorized OAuth apps and persistence mechanisms</li>\n</ol>\n<p><strong>‚ö†Ô∏è Critical:</strong> Complete steps 1-4 BEFORE rotating credentials, or the malware will steal your new keys.</p>\n<hr>\n<h2 id=\"protection-strategies\"><a href=\"#protection-strategies\" aria-hidden=\"true\" tabindex=\"-1\">Protection Strategies</a></h2>\n<p>Defending against Shai-Hulud requires a multi-layered protection approach:</p>\n<p><strong>Immediate Defense:</strong></p>\n<ul>\n<li><strong>Repository Containment</strong>: Privatize malicious repositories to cut off attacker access</li>\n<li><strong>Malware Removal</strong>: Eliminate infected packages before credential rotation</li>\n<li><strong>Access Revocation</strong>: Disable compromised runners and workflows</li>\n</ul>\n<p><strong>Credential Protection:</strong></p>\n<ul>\n<li><strong>Complete Rotation</strong>: Replace all GitHub tokens, npm credentials, and cloud keys</li>\n<li><strong>Scope Reduction</strong>: Minimize permissions on newly generated credentials</li>\n<li><strong>Multi-Factor Authentication</strong>: Enforce MFA on all developer and service accounts</li>\n</ul>\n<p><strong>Long-Term Prevention:</strong></p>\n<ul>\n<li><strong>Package Curation</strong>: Implement dependency scanning and approval workflows</li>\n<li><strong>Immaturity Policies</strong>: Block newly published package versions automatically</li>\n<li><strong>Continuous Monitoring</strong>: Set up alerts for suspicious repository creation and unusual package installations</li>\n</ul>\n<p>The following sections provide detailed step-by-step instructions for defending your organization against this sophisticated supply chain attack.</p>\n<hr>\n<p>Before continuing: <strong>DO NOT DELETE the GitHub repository</strong> that was created by Shai Hulud. Follow the guidance below.</p>\n<h1 id=\"understanding-the-compromise-what-is-leaked\"><a href=\"#understanding-the-compromise-what-is-leaked\" aria-hidden=\"true\" tabindex=\"-1\">Understanding the Compromise: What is Leaked?</a></h1>\n<p>The Shai-Hulud worm‚Äôs objective is to extract high-value credentials that facilitate lateral movement and further supply chain attacks. It achieves this by aggressively scanning the compromised developer environment. Using a stolen Developer GitHub Personal Access Token (PAT), the malware programmatically creates the exfiltration repository and commits files that categorize the stolen data.</p>\n<h2 id=\"the-compromised-repository-structure\"><a href=\"#the-compromised-repository-structure\" aria-hidden=\"true\" tabindex=\"-1\">The Compromised Repository Structure</a></h2>\n<p><img src=\"/img/RealTimePostImage/post/shai-hulud-remediation/example-repo.png\"></p>\n<p>The malware commits multiple <code>.json</code> files, all containing JSON objects that have been subjected to double Base64 encoding to provide a basic layer of obfuscation against simple secret scans:</p>\n<ul>\n<li><code>actionsSecrets.json</code>: This file contains credentials specifically designed for the <strong>GitHub Actions</strong> environment. These secrets are often non-personal service tokens with broad permissions, making them extremely valuable to the attacker for automating malicious deployments or accessing corporate infrastructure.</li>\n</ul>\n<details>\n<summary>View actionsSecrets.json example</summary>\n<pre><code class=\"language-json\">{\n  \"AWS_ACCESS_KEY_ID_SDK\": \"AKIA****KOI\",\n  \"AWS_SECRET_ACCESS_KEY_DEV\": \"MGcv*****bUR\",\n  \"GH_BOT_TOKEN\": \"ghp_*******8O8\",\n  \"NPM_AUTH_TOKEN\": \"NpmToken.ff*******a86\",\n  \"SECRET_KEY\": \"0eee*****a59\",\n  \"COCOAPODS_TRUNK_TOKEN\": \"8efb*****d607\",\n  \"TOKEN_ARTIFACTORY\": \"eyJ2*****SldU.eyJ*****ZGE2.YV7u*****oSQ\",\n  \"PHUB_EVIDENCER_SECRET_KEY_PRO\": \"HgV*****pU=\",\n  \"TENANT_ID\": \"6f2b*****94a9\",\n  \"CLIENT_SELPHID_SECRET\": \"VOph*****flJ\",\n  \"github_token\": \"ghs_7Q******sN\",\n  \"EXPO_TOKEN\": \"i67u****teI-\",\n  \"BROWSERSTACK_ACCESS_KEY\": \"N86j****nQzv\",\n  \"CLIENTSECRET_PRO\": \"bta****2RVr0\"\n}\n</code></pre>\n</details>\n<ul>\n<li><code>contents.json</code>: The primary file containing the victim's own GitHub token that was used to create the repository, along with initial system and account information.</li>\n</ul>\n<details>\n<summary>View contents.json example</summary>\n<pre><code class=\"language-json\">{\n  \"system\": {\n    \"platform\": \"darwin\",\n    \"architecture\": \"arm64\",\n    \"platformDetailed\": \"darwin\",\n    \"architectureDetailed\": \"arm64\",\n    \"hostname\": \"LT310\",\n    \"os_user\": {\n      \"homedir\": \"/Users/********\",\n      \"username\": \"********\",\n      \"shell\": \"/bin/zsh\",\n      \"uid\": 502,\n      \"gid\": 20\n    }\n  },\n  \"modules\": {\n    \"github\": {\n      \"authenticated\": true,\n      \"token\": \"ghp_bIQGBY8TW*************lGG2Z1d3rLz\",\n      \"username\": {\n        \"login\": \"********\",\n        \"name\": \"M******\",\n        \"email\": null,\n        \"publicRepos\": 6,\n        \"followers\": 0,\n        \"following\": 0,\n        \"createdAt\": \"2022-10-04T08:23:41Z\"\n      }\n    }\n  }\n}\n</code></pre>\n</details>\n<ul>\n<li><code>cloud.json</code>: Contains high-priority, high-risk credentials, specifically AWS, Azure, and Google Cloud Platform (GCP) access keys/secrets.</li>\n</ul>\n<details>\n<summary>View cloud.json example</summary>\n<pre><code class=\"language-json\">{\n  \"aws\": {\n    \"secrets\": [\n      {\n        \"name\": \"AWS_ACCESS_KEY_ID\",\n        \"value\": \"AKIAIOSFODNN7EXAMPLE\"\n      },\n      {\n        \"name\": \"AWS_SECRET_ACCESS_KEY\",\n        \"value\": \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"\n      },\n      {\n        \"name\": \"AWS_SESSION_TOKEN\",\n        \"value\": \"FwoGZXIvYXdzEBYaDEXAMPLETOKEN1234567890abcdefg\"\n      }\n    ]\n  },\n  \"gcp\": {\n    \"secrets\": [\n      {\n        \"name\": \"GCP_SERVICE_ACCOUNT_KEY\",\n        \"value\": \"eyJ0eXBlIjoic2VydmljZV9hY2NvdW50IiwiY2xpZW50X2VtYWlsIjoiZXhhbXBsZUBwcm9qZWN0LmlhbS5nc2VydmljZWFjY291bnQuY29tIn0=\"\n      },\n      {\n        \"name\": \"GCP_PROJECT_ID\",\n        \"value\": \"example-project-123456\"\n      }\n    ]\n  },\n  \"azure\": {\n    \"secrets\": [\n      {\n        \"name\": \"AZURE_CLIENT_ID\",\n        \"value\": \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\"\n      },\n      {\n        \"name\": \"AZURE_CLIENT_SECRET\",\n        \"value\": \"Abc8Q~EXAMPLE_SECRET_VALUE_1234567890abcdef\"\n      },\n      {\n        \"name\": \"AZURE_TENANT_ID\",\n        \"value\": \"98765432-abcd-efgh-ijkl-1234567890ab\"\n      }\n    ]\n  }\n}\n</code></pre>\n</details>\n<ul>\n<li><code>environment.json</code>: A complete dump of the compromised system's environment variables (<code>process.env</code>), often revealing sensitive API keys, database connection strings, and internal service credentials.</li>\n</ul>\n<p><img src=\"/img/RealTimePostImage/post/shai-hulud-remediation/env_secrets.png\">\n<strong>Example of GitHub repository created by Sha1-Hulud (2nd campaign) malware</strong></p>\n<ul>\n<li><code>truffleSecrets.json</code>: Credentials found by an aggressive file system scan using an embedded version of the open-source tool, <a href=\"https://github.com/trufflesecurity/trufflehog\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">TruffleHog</a>.</li>\n</ul>\n<details>\n<summary>View truffleSecrets.json example</summary>\n<pre><code class=\"language-json\">{\n  \"findings\": [\n    {\n      \"SourceMetadata\": {\n        \"Data\": {\n          \"Filesystem\": {\n            \"file\": \"/home/runner/work/my-project/.git/config\",\n            \"line\": 12\n          }\n        }\n      },\n      \"SourceName\": \"trufflehog - filesystem\",\n      \"DetectorType\": 8,\n      \"DetectorName\": \"Github\",\n      \"DetectorDescription\": \"GitHub Personal Access Token\",\n      \"Verified\": true,\n      \"Raw\": \"ghp_a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8\",\n      \"ExtraData\": {\n        \"rotation_guide\": \"https://howtorotate.com/docs/tutorials/github/\"\n      }\n    },\n    {\n      \"SourceMetadata\": {\n        \"Data\": {\n          \"Filesystem\": {\n            \"file\": \"/home/runner/work/my-project/config/credentials.json\",\n            \"line\": 5\n          }\n        }\n      },\n      \"SourceName\": \"trufflehog - filesystem\",\n      \"DetectorType\": 1039,\n      \"DetectorName\": \"JWT\",\n      \"DetectorDescription\": \"JSON Web Token\",\n      \"Verified\": true,\n      \"Raw\": \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWUsImlhdCI6MTUxNjIzOTAyMn0.POstGetfAytaZS82wHcjoTyoqhMyxXiWdR7Nn7A29DNSl0EiXLdwJ6xC6AfgZWF1bOsS_TuYI3OG85AmiExREkrS6tDfTQ2B3WXlrr-wp5AokiRbz3_oB4OxG-W9KcEEbDRcZc0nH3L7LzYptiy1PtAylQGxHTWZXtGz4ht0bAecBgmpdgXMguEIcoqPJ1n3pIWk_dUZegpqx0Lka21H6XxUTxiy8OcaarA8zdnPUnV6AmNP3ecFawIFYdvJB_cm-GvpCSbr8G8y_Mllj8f4x9nBH8pQux89_6gUY618iYv7tuPWBFfEbLxtF2pZS6YC1aSfLQxeNe8djT9YjpvRZA\",\n      \"ExtraData\": {\n        \"alg\": \"RS256\",\n        \"exp\": \"2025-12-01 00:00:00 +0000 UTC\",\n        \"iss\": \"https://auth.example.com\"\n      }\n    },\n    {\n      \"SourceMetadata\": {\n        \"Data\": {\n          \"Filesystem\": {\n            \"file\": \"/home/runner/work/my-project/scripts/deploy.sh\",\n            \"line\": 23\n          }\n        }\n      },\n      \"SourceName\": \"trufflehog - filesystem\",\n      \"DetectorType\": 15,\n      \"DetectorName\": \"PrivateKey\",\n      \"DetectorDescription\": \"RSA Private Key\",\n      \"Verified\": false,\n      \"Raw\": \"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEA2Z3qX2BTLS4e....[TRUNCATED]....\\n-----END RSA PRIVATE KEY-----\",\n      \"Redacted\": \"-----BEGIN RSA PRIVATE KEY-----\\nMIIEpAIBAAKCAQEA2Z3qX2BTLS4e\"\n    },\n    {\n      \"SourceMetadata\": {\n        \"Data\": {\n          \"Filesystem\": {\n            \"file\": \"/home/runner/work/my-project/.env\",\n            \"line\": 8\n          }\n        }\n      },\n      \"SourceName\": \"trufflehog - filesystem\",\n      \"DetectorType\": 17,\n      \"DetectorName\": \"URI\",\n      \"DetectorDescription\": \"URL with embedded credentials\",\n      \"Verified\": false,\n      \"Raw\": \"postgresql://admin:SuperSecret123@db.internal.example.com:5432/production\",\n      \"Redacted\": \"postgresql://admin:********@db.internal.example.com:5432/production\"\n    },\n    {\n      \"SourceMetadata\": {\n        \"Data\": {\n          \"Filesystem\": {\n            \"file\": \"/home/runner/work/my-project/src/services/aws.js\",\n            \"line\": 15\n          }\n        }\n      },\n      \"SourceName\": \"trufflehog - filesystem\",\n      \"DetectorType\": 1,\n      \"DetectorName\": \"AWS\",\n      \"DetectorDescription\": \"AWS Access Key\",\n      \"Verified\": true,\n      \"Raw\": \"AKIAIOSFODNN7EXAMPLE\",\n      \"RawV2\": \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"\n    }\n  ],\n  \"executionTime\": 45230,\n  \"exitCode\": 0,\n  \"verified_secrets\": 3,\n  \"unverified_secrets\": 2\n}\n</code></pre>\n</details>\n<h2 id=\"persistency-through-github-action\"><a href=\"#persistency-through-github-action\" aria-hidden=\"true\" tabindex=\"-1\">Persistency through GitHub Action</a></h2>\n<p>The Shai-Hulud (1st) and Sha1-Hulud (2nd) campaigns specifically target GitHub Actions environments with two distinct, high-impact mechanisms:</p>\n<ol>\n<li><strong>Secret Exfiltration via Malicious Workflow:</strong> The malware pushes a temporary, malicious workflow (e.g., <code>.github/workflows/formatter_123456789.yml</code> or <code>discussion.yaml</code>) to compromise repositories. This workflow's sole purpose is to list and collect all secrets defined in the repository's <strong>GitHub Secrets</strong> section and upload them as the <strong><code>actionsSecrets.json</code></strong> file to the exfiltration repo.</li>\n<li><strong>Persistence via Self-Hosted Runner:</strong> The malware registers the infected machine (if it is a CI runner or has the necessary permissions) as a <strong>self-hosted runner</strong> named something identifiable like <strong><code>SHA1HULUD</code></strong>, which allows the attacker continuous, remote access to the organization's network and resources.</li>\n</ol>\n<p>This structured dump provides the attacker with a complete dossier for continued operation.</p>\n<h1 id=\"the-incident-response-plan-where-to-start\"><a href=\"#the-incident-response-plan-where-to-start\" aria-hidden=\"true\" tabindex=\"-1\">The Incident Response Plan: Where to Start</a></h1>\n<h2 id=\"1-containment-lock-down-the-exfiltration-channel\"><a href=\"#1-containment-lock-down-the-exfiltration-channel\" aria-hidden=\"true\" tabindex=\"-1\">1. Containment: Lock Down the Exfiltration Channel</a></h2>\n<ul>\n<li><strong>Action: DO NOT DELETE THE GITHUB REPOSITORY</strong>. Instead, immediately navigate to the suspicious <strong>GitHub repository</strong> and change its visibility from <strong>Public to Private</strong> in the settings. *In case you are not able to change the visibility, <strong>clone the repository and then delete it*</strong>.\n<video src=\"/img/RealTimePostImage/post/shai-hulud-remediation/privatize-github-repo.mp4\" controls></video></li>\n<li><strong>Why:</strong> This instantly terminates public access to the data, regardless of the encoding. The repository should not be deleted since it is your primary forensic evidence.</li>\n</ul>\n<h2 id=\"2-eradication-neutralize-the-github-action-and-remove-the-malicious-package\"><a href=\"#2-eradication-neutralize-the-github-action-and-remove-the-malicious-package\" aria-hidden=\"true\" tabindex=\"-1\">2. Eradication: Neutralize the GitHub Action and Remove the Malicious Package</a></h2>\n<p><strong>This step is mandatory <em>before</em> rotating credentials. If you rotate keys while the malware is still present, it will simply steal the new keys.</strong></p>\n<h3 id=\"action-a-disable--remove-malicious-runner-persistence\"><a href=\"#action-a-disable--remove-malicious-runner-persistence\" aria-hidden=\"true\" tabindex=\"-1\">Action A: Disable / Remove Malicious Runner (Persistence)</a></h3>\n<ul>\n<li><strong>Action</strong>: Navigate to your <strong>GitHub Settings</strong> (or Organization/Enterprise Settings) ‚Üí <strong>Actions</strong> ‚Üí <strong>Runners</strong>.</li>\n<li>Find and <strong>immediately disable or remove</strong> any self-hosted runner named <strong><code>SHA1HULUD</code></strong> or any other unrecognized runner added recently.</li>\n<li><strong>Why:</strong> This eliminates the attacker's persistent backdoor access to your build network.</li>\n</ul>\n<h3 id=\"action-b-clean-repositories-workflow-removal\"><a href=\"#action-b-clean-repositories-workflow-removal\" aria-hidden=\"true\" tabindex=\"-1\">Action B: Clean Repositories (Workflow Removal)</a></h3>\n<ul>\n<li>Check compromised repositories for new files in the <code>.github/workflows/</code> directory (e.g., <code>formatter_*.yml</code>). Revert/Delete these malicious workflow files.</li>\n</ul>\n<h3 id=\"action-c-remove-the-malicious-packages\"><a href=\"#action-c-remove-the-malicious-packages\" aria-hidden=\"true\" tabindex=\"-1\">Action C: Remove the Malicious Packages</a></h3>\n<ul>\n<li><strong>Remove:</strong> Completely delete the project's dependency artifacts locally (<code>rm -rf node_modules</code>) and clear the local cache (<code>npm cache clean --force</code>).</li>\n<li><strong>Reinstall Safely</strong>: Update your <code>package.json</code> to replace the malicious package‚Äôs version (<a href=\"https://research.jfrog.com/post/shai-hulud-the-second-coming/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://research.jfrog.com/post/shai-hulud-the-second-coming/</a>) with a known, safe version, then re-install the package locally (<code>npm ci</code>).</li>\n<li><strong>Re-publish package</strong>: If you are a package maintainer and a malicious package was released under your name, ensure you <strong>re-publish the package</strong> with a new, safe release.</li>\n</ul>\n<h3 id=\"how-can-i-identify-shai-hulud-infected-packages-on-my-local-disk\"><a href=\"#how-can-i-identify-shai-hulud-infected-packages-on-my-local-disk\" aria-hidden=\"true\" tabindex=\"-1\">How can I identify Shai-Hulud infected packages on my local disk?</a></h3>\n<ul>\n<li><strong>Identify:</strong> Use the detection script below to look on disk for a malicious package or a malicious indicators (Credit: <a href=\"https://github.com/Cobenian/shai-hulud-detect\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Cobenian/shai-hulud-detect</a>).</li>\n</ul>\n<blockquote>\n<p><strong>Security Note:</strong> We have embedded the full source code below to ensure the integrity and availability of the detection tool. Mirroring the script here eliminates dependencies on external repositories that could potentially be modified or compromised in the future, guaranteeing a safe and verifiable version for your incident response.</p>\n</blockquote>\n<details>\n<summary>Click to view shai-hulud-detector.sh</summary>\n<pre><code class=\"language-bash\">#!/usr/bin/env bash\n\n# Shai-Hulud NPM Supply Chain Attack Detection Script\n# Detects indicators of compromise from September 2025 and November 2025 npm attacks\n# Includes detection for \"Shai-Hulud: The Second Coming\" (fake Bun runtime attack)\n# Usage: ./shai-hulud-detector.sh &#x3C;directory_to_scan>\n#\n# Requires: Bash 5.0+\n\n# Require Bash 5.0+ for associative arrays, mapfile, and modern features\nif [[ -z \"${BASH_VERSINFO[0]}\" ]] || [[ \"${BASH_VERSINFO[0]}\" -lt 5 ]]; then\n    echo \"ERROR: Shai-Hulud Detector requires Bash 5.0 or newer.\"\n    echo \"You appear to be running: ${BASH_VERSION:-unknown}.\"\n    echo\n    echo \"macOS:   brew install bash &#x26;&#x26; run with:  /opt/homebrew/bin/bash $0 ...\"\n    echo \"Linux:   install a current bash via your package manager (bash 5.x is standard on modern distros).\"\n    exit 1\nfi\n\nset -eo pipefail\n\n# Script directory for locating companion files (compromised-packages.txt)\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" &#x26;&#x26; pwd)\"\n\n# Global temp directory for file-based storage\nTEMP_DIR=\"\"\n\n# Global variables for risk tracking (used for exit codes)\nhigh_risk=0\nmedium_risk=0\n\n# Function: create_temp_dir\n# Purpose: Create cross-platform temporary directory for findings storage\n# Args: None\n# Modifies: TEMP_DIR (global variable)\n# Returns: 0 on success, exits on failure\ncreate_temp_dir() {\n    local temp_base=\"${TMPDIR:-${TMP:-${TEMP:-/tmp}}}\"\n\n    if command -v mktemp >/dev/null 2>&#x26;1; then\n        # Try mktemp with our preferred pattern\n        TEMP_DIR=$(mktemp -d -t shai-hulud-detect-XXXXXX 2>/dev/null || true) || \\\n        TEMP_DIR=$(mktemp -d 2>/dev/null || true) || \\\n        TEMP_DIR=\"$temp_base/shai-hulud-detect-$$-$(date +%s)\"\n    else\n        # Fallback for systems without mktemp (rare with bash)\n        TEMP_DIR=\"$temp_base/shai-hulud-detect-$$-$(date +%s)\"\n    fi\n\n    mkdir -p \"$TEMP_DIR\" || {\n        echo \"Error: Cannot create temporary directory\"\n        exit 1\n    }\n\n    # Create findings files\n    touch \"$TEMP_DIR/workflow_files.txt\"\n    touch \"$TEMP_DIR/malicious_hashes.txt\"\n    touch \"$TEMP_DIR/compromised_found.txt\"\n    touch \"$TEMP_DIR/suspicious_found.txt\"\n    touch \"$TEMP_DIR/suspicious_content.txt\"\n    touch \"$TEMP_DIR/crypto_patterns.txt\"\n    touch \"$TEMP_DIR/git_branches.txt\"\n    touch \"$TEMP_DIR/postinstall_hooks.txt\"\n    touch \"$TEMP_DIR/trufflehog_activity.txt\"\n    touch \"$TEMP_DIR/shai_hulud_repos.txt\"\n    touch \"$TEMP_DIR/namespace_warnings.txt\"\n    touch \"$TEMP_DIR/low_risk_findings.txt\"\n    touch \"$TEMP_DIR/integrity_issues.txt\"\n    touch \"$TEMP_DIR/typosquatting_warnings.txt\"\n    touch \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n    touch \"$TEMP_DIR/lockfile_safe_versions.txt\"\n    touch \"$TEMP_DIR/bun_setup_files.txt\"\n    touch \"$TEMP_DIR/bun_environment_files.txt\"\n    touch \"$TEMP_DIR/new_workflow_files.txt\"\n    touch \"$TEMP_DIR/github_sha1hulud_runners.txt\"\n    touch \"$TEMP_DIR/preinstall_bun_patterns.txt\"\n    touch \"$TEMP_DIR/second_coming_repos.txt\"\n    touch \"$TEMP_DIR/actions_secrets_files.txt\"\n    touch \"$TEMP_DIR/discussion_workflows.txt\"\n    touch \"$TEMP_DIR/github_runners.txt\"\n    touch \"$TEMP_DIR/malicious_hashes.txt\"\n    touch \"$TEMP_DIR/destructive_patterns.txt\"\n    touch \"$TEMP_DIR/trufflehog_patterns.txt\"\n}\n\n# Function: cleanup_temp_files\n# Purpose: Clean up temporary directory on script exit, interrupt, or termination\n# Args: None (uses $? for exit code)\n# Modifies: Removes temp directory and all contents\n# Returns: Exits with original script exit code\ncleanup_temp_files() {\n    local exit_code=$?\n    if [[ -n \"$TEMP_DIR\" &#x26;&#x26; -d \"$TEMP_DIR\" ]]; then\n        rm -rf \"$TEMP_DIR\"\n    fi\n    exit $exit_code\n}\n\n# Set trap for cleanup on exit, interrupt, or termination\ntrap cleanup_temp_files EXIT INT TERM\n\n# Color codes for output\nRED='\\033[0;31m'\nYELLOW='\\033[1;33m'\nGREEN='\\033[0;32m'\nBLUE='\\033[0;34m'\nORANGE='\\033[38;5;172m'  # Muted orange for stage headers (256-color mode)\nNC='\\033[0m' # No Color\n\n# Known malicious file hashed (source: https://socket.dev/blog/ongoing-supply-chain-attack-targets-crowdstrike-npm-packages)\nMALICIOUS_HASHLIST=(\n    \"de0e25a3e6c1e1e5998b306b7141b3dc4c0088da9d7bb47c1c00c91e6e4f85d6\"\n    \"81d2a004a1bca6ef87a1caf7d0e0b355ad1764238e40ff6d1b1cb77ad4f595c3\"\n    \"83a650ce44b2a9854802a7fb4c202877815274c129af49e6c2d1d5d5d55c501e\"\n    \"4b2399646573bb737c4969563303d8ee2e9ddbd1b271f1ca9e35ea78062538db\"\n    \"dc67467a39b70d1cd4c1f7f7a459b35058163592f4a9e8fb4dffcbba98ef210c\"\n    \"46faab8ab153fae6e80e7cca38eab363075bb524edd79e42269217a083628f09\"\n    \"b74caeaa75e077c99f7d44f46daaf9796a3be43ecf24f2a1fd381844669da777\"\n    \"86532ed94c5804e1ca32fa67257e1bb9de628e3e48a1f56e67042dc055effb5b\" # test-cases/multi-hash-detection/file1.js\n    \"aba1fcbd15c6ba6d9b96e34cec287660fff4a31632bf76f2a766c499f55ca1ee\" # test-cases/multi-hash-detection/file2.js\n)\n\nPARALLELISM=4\nif [[ \"$OSTYPE\" == \"linux-gnu\"* ]]; then\n  PARALLELISM=$(nproc)\nelif [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n  PARALLELISM=$(sysctl -n hw.ncpu)\nfi\n\n# Timing variables\nSCAN_START_TIME=0\n\n# Function: get_elapsed_time\n# Purpose: Get elapsed time since scan start in seconds\n# Returns: Time in format \"X.XXXs\"\nget_elapsed_time() {\n    local now=$(date +%s%N 2>/dev/null || echo \"$(date +%s)000000000\")\n    local elapsed_ns=$((now - SCAN_START_TIME))\n    local elapsed_s=$((elapsed_ns / 1000000000))\n    local elapsed_ms=$(((elapsed_ns % 1000000000) / 1000000))\n    printf \"%d.%03ds\" \"$elapsed_s\" \"$elapsed_ms\"\n}\n\n# Function: print_stage_complete\n# Purpose: Print stage completion with elapsed time\n# Args: $1 = stage name\nprint_stage_complete() {\n    local stage_name=$1\n    local elapsed=$(get_elapsed_time)\n    print_status \"$BLUE\" \"   $stage_name completed [$elapsed]\"\n}\n\n# Associative arrays for O(1) lookups (Bash 5.0+ feature)\ndeclare -A COMPROMISED_PACKAGES_MAP    # \"package:version\" -> 1\ndeclare -A COMPROMISED_NAMESPACES_MAP  # \"@namespace\" -> 1\n\n# Function: load_compromised_packages\n# Purpose: Load compromised package database from external file or fallback list\n# Args: None (reads from compromised-packages.txt in script directory)\n# Modifies: COMPROMISED_PACKAGES_MAP (global associative array)\n# Returns: Populates COMPROMISED_PACKAGES_MAP for O(1) lookups\nload_compromised_packages() {\n    local packages_file=\"$SCRIPT_DIR/compromised-packages.txt\"\n    local count=0\n\n    if [[ -f \"$packages_file\" ]]; then\n        # Use mapfile to read all valid lines at once, then populate associative array\n        local -a raw_packages\n        mapfile -t raw_packages &#x3C; &#x3C;(\n            grep -v '^[[:space:]]*#' \"$packages_file\" | \\\n            grep -E '^[a-zA-Z@][^:]+:[0-9]+\\.[0-9]+\\.[0-9]+' | \\\n            tr -d $'\\r'\n        )\n\n        # Populate associative array for O(1) lookups\n        for pkg in \"${raw_packages[@]}\"; do\n            COMPROMISED_PACKAGES_MAP[\"$pkg\"]=1\n            ((count++)) || true  # Prevent errexit when count starts at 0\n        done\n\n        print_status \"$BLUE\" \"üì¶ Loaded $count compromised packages from $packages_file (O(1) lookup enabled)\"\n    else\n        # Fallback to embedded list if file not found\n        print_status \"$YELLOW\" \"‚ö†Ô∏è  Warning: $packages_file not found, using embedded package list\"\n        local fallback_packages=(\n            \"@ctrl/tinycolor:4.1.0\"\n            \"@ctrl/tinycolor:4.1.1\"\n            \"@ctrl/tinycolor:4.1.2\"\n            \"@ctrl/deluge:1.2.0\"\n            \"angulartics2:14.1.2\"\n            \"koa2-swagger-ui:5.11.1\"\n            \"koa2-swagger-ui:5.11.2\"\n        )\n        for pkg in \"${fallback_packages[@]}\"; do\n            COMPROMISED_PACKAGES_MAP[\"$pkg\"]=1\n        done\n    fi\n}\n\n# Known compromised namespaces - packages in these namespaces may be compromised\n# Stored in both array (for iteration) and associative array (for O(1) lookup)\nCOMPROMISED_NAMESPACES=(\n    \"@crowdstrike\"\n    \"@art-ws\"\n    \"@ngx\"\n    \"@ctrl\"\n    \"@nativescript-community\"\n    \"@ahmedhfarag\"\n    \"@operato\"\n    \"@teselagen\"\n    \"@things-factory\"\n    \"@hestjs\"\n    \"@nstudio\"\n    \"@basic-ui-components-stc\"\n    \"@nexe\"\n    \"@thangved\"\n    \"@tnf-dev\"\n    \"@ui-ux-gang\"\n    \"@yoobic\"\n)\n\n# Populate namespace associative array for O(1) lookups\nfor ns in \"${COMPROMISED_NAMESPACES[@]}\"; do\n    COMPROMISED_NAMESPACES_MAP[\"$ns\"]=1\ndone\n\n# Function: is_compromised_package\n# Purpose: O(1) lookup to check if a package:version is compromised\n# Args: $1 = package:version string\n# Returns: 0 if compromised, 1 if not\nis_compromised_package() {\n    [[ -v COMPROMISED_PACKAGES_MAP[\"$1\"] ]]\n}\n\n# Function: is_compromised_namespace\n# Purpose: O(1) lookup to check if a namespace is compromised\n# Args: $1 = @namespace string\n# Returns: 0 if compromised, 1 if not\nis_compromised_namespace() {\n    [[ -v COMPROMISED_NAMESPACES_MAP[\"$1\"] ]]\n}\n\n# Function: cleanup_and_exit\n# Purpose: Clean up background processes and temp files when script is interrupted\n# Args: None\n# Modifies: Kills all background jobs, removes temp files\n# Returns: Exits with code 130 (standard for Ctrl-C interruption)\ncleanup_and_exit() {\n    print_status \"$YELLOW\" \"üõë Scan interrupted by user. Cleaning up...\"\n\n    # Kill all background jobs (more portable approach)\n    local job_pids\n    job_pids=$(jobs -p 2>/dev/null || true)\n    if [[ -n \"$job_pids\" ]]; then\n        echo \"$job_pids\" | while read -r pid; do\n            [[ -n \"$pid\" ]] &#x26;&#x26; kill \"$pid\" 2>/dev/null || true\n        done\n\n        # Wait a moment for jobs to terminate\n        sleep 0.5\n\n        # Force kill any remaining processes\n        echo \"$job_pids\" | while read -r pid; do\n            [[ -n \"$pid\" ]] &#x26;&#x26; kill -9 \"$pid\" 2>/dev/null || true\n        done\n    fi\n\n    # Clean up temp directory\n    if [[ -n \"$TEMP_DIR\" &#x26;&#x26; -d \"$TEMP_DIR\" ]]; then\n        rm -rf \"$TEMP_DIR\"\n    fi\n\n    print_status \"$NC\" \"Cleanup complete. Exiting.\"\n    exit 130\n}\n\n# Phase 2: Bash 3.x Compatible In-Memory Caching System\n# Uses temp files in memory (tmpfs) for compatibility with older Bash versions\n\n# Function: get_cached_file_hash\n# Purpose: Get cached SHA256 hash using tmpfs for near-memory speed\n# Args: $1 = file_path (absolute path to file)\n# Modifies: Creates small cache files in TEMP_DIR for reuse\n# Returns: Echoes SHA256 hash of file\nget_cached_file_hash() {\n    local file_path=\"$1\"\n\n    # Create cache key from file path, size, and modification time\n    local file_size file_mtime cache_key hash_cache_file\n    file_size=$(stat -f%z \"$file_path\" 2>/dev/null || stat -c%s \"$file_path\" 2>/dev/null || echo \"0\")\n    file_mtime=$(stat -f%m \"$file_path\" 2>/dev/null || stat -c%Y \"$file_path\" 2>/dev/null || echo \"0\")\n    cache_key=$(echo \"${file_path}:${file_size}:${file_mtime}\" | shasum 2>/dev/null | cut -d' ' -f1 || echo \"${file_path//\\//_}_${file_size}_${file_mtime}\")\n    hash_cache_file=\"$TEMP_DIR/hcache_$cache_key\"\n\n    # Check cache first - small file reads are very fast\n    if [[ -f \"$hash_cache_file\" ]]; then\n        cat \"$hash_cache_file\"\n        return 0\n    fi\n\n    # Calculate hash and store in cache\n    local file_hash=\"\"\n    if command -v sha256sum >/dev/null 2>&#x26;1; then\n        file_hash=$(sha256sum \"$file_path\" 2>/dev/null | cut -d' ' -f1)\n    elif command -v shasum >/dev/null 2>&#x26;1; then\n        file_hash=$(shasum -a 256 \"$file_path\" 2>/dev/null | cut -d' ' -f1)\n    fi\n\n    # Store in cache for future lookups\n    if [[ -n \"$file_hash\" ]]; then\n        echo \"$file_hash\" > \"$hash_cache_file\"\n        echo \"$file_hash\"\n    fi\n}\n\n# Function: get_cached_package_dependencies\n# Purpose: Get cached package dependencies using tmpfs storage\n# Args: $1 = package_file (path to package.json)\n# Modifies: Creates cache files in TEMP_DIR\n# Returns: Echoes package dependencies in name:version format\nget_cached_package_dependencies() {\n    local package_file=\"$1\"\n\n    # Create cache key from file path, size, and modification time\n    local file_size file_mtime cache_key deps_cache_file\n    file_size=$(stat -f%z \"$package_file\" 2>/dev/null || stat -c%s \"$package_file\" 2>/dev/null || echo \"0\")\n    file_mtime=$(stat -f%m \"$package_file\" 2>/dev/null || stat -c%Y \"$package_file\" 2>/dev/null || echo \"0\")\n    cache_key=$(echo \"${package_file}:${file_size}:${file_mtime}\" | shasum 2>/dev/null | cut -d' ' -f1 || echo \"${package_file//\\//_}_${file_size}_${file_mtime}\")\n    deps_cache_file=\"$TEMP_DIR/dcache_$cache_key\"\n\n    # Check cache first\n    if [[ -f \"$deps_cache_file\" ]]; then\n        cat \"$deps_cache_file\"\n        return 0\n    fi\n\n    # Extract dependencies and store in cache\n    local deps_output\n    deps_output=$(awk '/\"dependencies\":|\"devDependencies\":/{flag=1;next}/}/{flag=0}flag' \"$package_file\" 2>/dev/null || true)\n\n    if [[ -n \"$deps_output\" ]]; then\n        echo \"$deps_output\" > \"$deps_cache_file\"\n        echo \"$deps_output\"\n    fi\n}\n\n# File-based storage for findings (replaces global arrays for memory efficiency)\n# Files created in create_temp_dir() function:\n# - workflow_files.txt, malicious_hashes.txt, compromised_found.txt\n# - suspicious_found.txt, suspicious_content.txt, crypto_patterns.txt\n# - git_branches.txt, postinstall_hooks.txt, trufflehog_activity.txt\n# - shai_hulud_repos.txt, namespace_warnings.txt, low_risk_findings.txt\n# - integrity_issues.txt, typosquatting_warnings.txt, network_exfiltration_warnings.txt\n# - lockfile_safe_versions.txt, bun_setup_files.txt, bun_environment_files.txt\n# - new_workflow_files.txt, github_sha1hulud_runners.txt, preinstall_bun_patterns.txt\n# - second_coming_repos.txt, actions_secrets_files.txt, trufflehog_patterns.txt\n\n# Function: usage\n# Purpose: Display help message and exit\n# Args: None\n# Modifies: None\n# Returns: Exits with code 1\nusage() {\n    echo \"Usage: $0 [--paranoid] [--parallelism N] &#x3C;directory_to_scan>\"\n    echo\n    echo \"OPTIONS:\"\n    echo \"  --paranoid         Enable additional security checks (typosquatting, network patterns)\"\n    echo \"                     These are general security features, not specific to Shai-Hulud\"\n    echo \"  --parallelism N    Set the number of threads to use for parallelized steps (current: ${PARALLELISM})\"\n    echo \"\"\n    echo \"EXAMPLES:\"\n    echo \"  $0 /path/to/your/project                    # Core Shai-Hulud detection only\"\n    echo \"  $0 --paranoid /path/to/your/project         # Core + advanced security checks\"\n    exit 1\n}\n\n# Function: print_status\n# Purpose: Print colored status messages to console\n# Args: $1 = color code (RED, YELLOW, GREEN, BLUE, NC), $2 = message text\n# Modifies: None (outputs to stdout)\n# Returns: Prints colored message\nprint_status() {\n    local color=$1\n    local message=$2\n    echo -e \"${color}${message}${NC}\"\n}\n\n# Function: show_file_preview\n# Purpose: Display file context for HIGH RISK findings only\n# Args: $1 = file_path, $2 = context description\n# Modifies: None (outputs to stdout)\n# Returns: Prints formatted file preview box for HIGH RISK items only\nshow_file_preview() {\n    local file_path=$1\n    local context=\"$2\"\n\n    # Only show file preview for HIGH RISK items to reduce noise\n    if [[ \"$context\" == *\"HIGH RISK\"* ]]; then\n        echo -e \"   ${BLUE}‚îå‚îÄ File: $file_path${NC}\"\n        echo -e \"   ${BLUE}‚îÇ  Context: $context${NC}\"\n        echo -e \"   ${BLUE}‚îî‚îÄ${NC}\"\n        echo\n    fi\n}\n\n# Function: show_progress\n# Purpose: Display real-time progress indicator for file scanning operations\n# Args: $1 = current files processed, $2 = total files to process\n# Modifies: None (outputs to stderr with ANSI escape codes)\n# Returns: Prints \"X / Y checked (Z %)\" with line clearing\nshow_progress() {\n    local current=$1\n    local total=$2\n    local percent=0\n    [[ $total -gt 0 ]] &#x26;&#x26; percent=$((current * 100 / total))\n    echo -ne \"\\r\\033[K$current / $total checked ($percent %)\"\n}\n\n# Function: count_files\n# Purpose: Count files matching find criteria, returns clean integer\n# Args: All arguments passed to find command (e.g., path, -name, -type)\n# Modifies: None\n# Returns: Integer count of matching files (strips whitespace)\ncount_files() {\n    (find \"$@\" 2>/dev/null || true) | wc -l | tr -d ' '\n}\n\n# Function: collect_all_files\n# Purpose: Single comprehensive file collection to replace 20+ separate find operations\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: Creates categorized temp files for all functions to use\n# Returns: Populates temp files with file paths by category\ncollect_all_files() {\n    local scan_dir=\"$1\"\n\n    # Ensure temp directory exists\n    [[ -d \"$TEMP_DIR\" ]] || mkdir -p \"$TEMP_DIR\"\n\n    # Single comprehensive find operation for all file types needed (silent)\n    {\n        find \"$scan_dir\" \\( \\\n            -name \"*.js\" -o -name \"*.ts\" -o -name \"*.json\" -o -name \"*.mjs\" -o \\\n            -name \"*.yml\" -o -name \"*.yaml\" -o \\\n            -name \"*.py\" -o -name \"*.sh\" -o -name \"*.bat\" -o -name \"*.ps1\" -o -name \"*.cmd\" -o \\\n            -name \"package.json\" -o \\\n            -name \"package-lock.json\" -o -name \"yarn.lock\" -o -name \"pnpm-lock.yaml\" -o \\\n            -name \"shai-hulud-workflow.yml\" -o \\\n            -name \"setup_bun.js\" -o -name \"bun_environment.js\" -o \\\n            -name \"actionsSecrets.json\" -o \\\n            -name \"*trufflehog*\" -o \\\n            -name \"formatter_*.yml\" \\\n        \\) -type f 2>/dev/null || true\n    } > \"$TEMP_DIR/all_files_raw.txt\"\n\n    # Also collect directories in a separate operation (silent)\n    {\n        find \"$scan_dir\" -name \".git\" -type d 2>/dev/null || true | sed 's|/.git$||'\n    } > \"$TEMP_DIR/git_repos.txt\"\n\n    {\n        find \"$scan_dir\" -type d \\( -name \".dev-env\" -o -name \"*shai*hulud*\" \\) 2>/dev/null || true\n    } > \"$TEMP_DIR/suspicious_dirs.txt\"\n\n    # Categorize files for specific functions using grep (much faster than separate finds)\n    grep \"package\\.json$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/package_files.txt\" 2>/dev/null || touch \"$TEMP_DIR/package_files.txt\"\n    grep \"\\.\\(js\\|ts\\|json\\|mjs\\)$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/code_files.txt\" 2>/dev/null || touch \"$TEMP_DIR/code_files.txt\"\n    grep \"\\.\\(yml\\|yaml\\)$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/yaml_files.txt\" 2>/dev/null || touch \"$TEMP_DIR/yaml_files.txt\"\n    grep \"\\.\\(py\\|sh\\|bat\\|ps1\\|cmd\\)$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/script_files.txt\" 2>/dev/null || touch \"$TEMP_DIR/script_files.txt\"\n    grep \"\\(package-lock\\.json\\|yarn\\.lock\\|pnpm-lock\\.yaml\\)$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/lockfiles.txt\" 2>/dev/null || touch \"$TEMP_DIR/lockfiles.txt\"\n    grep \"shai-hulud-workflow\\.yml$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/workflow_files_found.txt\" 2>/dev/null || touch \"$TEMP_DIR/workflow_files_found.txt\"\n    grep \"setup_bun\\.js$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/setup_bun_files.txt\" 2>/dev/null || touch \"$TEMP_DIR/setup_bun_files.txt\"\n    grep \"bun_environment\\.js$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/bun_environment_files.txt\" 2>/dev/null || touch \"$TEMP_DIR/bun_environment_files.txt\"\n    grep \"actionsSecrets\\.json$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/actions_secrets_found.txt\" 2>/dev/null || touch \"$TEMP_DIR/actions_secrets_found.txt\"\n    grep \"trufflehog\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/trufflehog_files.txt\" 2>/dev/null || touch \"$TEMP_DIR/trufflehog_files.txt\"\n    grep \"formatter_.*\\.yml$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/formatter_workflows.txt\" 2>/dev/null || touch \"$TEMP_DIR/formatter_workflows.txt\"\n\n    # Filter GitHub workflow files specifically\n    grep \"/.github/workflows/.*\\.ya\\?ml$\" \"$TEMP_DIR/all_files_raw.txt\" > \"$TEMP_DIR/github_workflows.txt\" 2>/dev/null || touch \"$TEMP_DIR/github_workflows.txt\"\n}\n\n# Function: check_workflow_files\n# Purpose: Detect malicious shai-hulud-workflow.yml files in project directories\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: WORKFLOW_FILES (global array)\n# Returns: Populates WORKFLOW_FILES array with paths to suspicious workflow files\ncheck_workflow_files() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for malicious workflow files...\"\n\n    # Use pre-categorized files from collect_all_files (performance optimization)\n    while IFS= read -r file; do\n        if [[ -f \"$file\" ]]; then\n            echo \"$file\" >> \"$TEMP_DIR/workflow_files.txt\"\n        fi\n    done &#x3C; \"$TEMP_DIR/workflow_files_found.txt\"\n}\n\n# Function: check_bun_attack_files\n# Purpose: Detect November 2025 \"Shai-Hulud: The Second Coming\" Bun attack files\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: $TEMP_DIR/bun_setup_files.txt, bun_environment_files.txt, malicious_hashes.txt\n# Returns: Populates temp files with paths to suspicious Bun-related malicious files\ncheck_bun_attack_files() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for November 2025 Bun attack files...\"\n\n    # Known malicious file hashes from Koi.ai incident report\n    local setup_bun_hashes=(\n        \"a3894003ad1d293ba96d77881ccd2071446dc3f65f434669b49b3da92421901a\"\n    )\n\n    local bun_environment_hashes=(\n        \"62ee164b9b306250c1172583f138c9614139264f889fa99614903c12755468d0\"\n        \"f099c5d9ec417d4445a0328ac0ada9cde79fc37410914103ae9c609cbc0ee068\"\n        \"cbb9bc5a8496243e02f3cc080efbe3e4a1430ba0671f2e43a202bf45b05479cd\"\n    )\n\n    # Look for setup_bun.js files (fake Bun runtime installation)\n    # Use pre-categorized files from collect_all_files (performance optimization)\n    if [[ -s \"$TEMP_DIR/setup_bun_files.txt\" ]]; then\n        while IFS= read -r file; do\n            if [[ -f \"$file\" ]]; then\n                echo \"$file\" >> \"$TEMP_DIR/bun_setup_files.txt\"\n\n                # Phase 2: Use in-memory cached hash calculation for performance\n                local file_hash=$(get_cached_file_hash \"$file\")\n\n                if [[ -n \"$file_hash\" ]]; then\n                    for known_hash in \"${setup_bun_hashes[@]}\"; do\n                        if [[ \"$file_hash\" == \"$known_hash\" ]]; then\n                            echo \"$file:SHA256=$file_hash (CONFIRMED MALICIOUS - Koi.ai IOC)\" >> \"$TEMP_DIR/malicious_hashes.txt\"\n                            break\n                        fi\n                    done\n                fi\n            fi\n        done &#x3C; \"$TEMP_DIR/setup_bun_files.txt\"\n    fi\n\n    # Look for bun_environment.js files (10MB+ obfuscated payload)\n    # Use pre-categorized files from collect_all_files (performance optimization)\n    if [[ -s \"$TEMP_DIR/bun_environment_files.txt\" ]]; then\n        while IFS= read -r file; do\n            if [[ -f \"$file\" ]]; then\n                echo \"$file\" >> \"$TEMP_DIR/bun_environment_files_found.txt\"\n\n                # Phase 2: Use in-memory cached hash calculation for performance\n                local file_hash=$(get_cached_file_hash \"$file\")\n\n                if [[ -n \"$file_hash\" ]]; then\n                    for known_hash in \"${bun_environment_hashes[@]}\"; do\n                        if [[ \"$file_hash\" == \"$known_hash\" ]]; then\n                            echo \"$file:SHA256=$file_hash (CONFIRMED MALICIOUS - Koi.ai IOC)\" >> \"$TEMP_DIR/malicious_hashes.txt\"\n                            break\n                        fi\n                    done\n                fi\n            fi\n        done &#x3C; \"$TEMP_DIR/bun_environment_files.txt\"\n    fi\n}\n\n# Function: check_new_workflow_patterns\n# Purpose: Detect November 2025 new workflow file patterns and actionsSecrets.json\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: NEW_WORKFLOW_FILES, ACTIONS_SECRETS_FILES (global arrays)\n# Returns: Populates arrays with paths to new attack pattern files\ncheck_new_workflow_patterns() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for new workflow patterns...\"\n\n    # Look for formatter_123456789.yml workflow files\n    # Use pre-categorized files from collect_all_files (performance optimization)\n    if [[ -s \"$TEMP_DIR/formatter_workflows.txt\" ]]; then\n        while IFS= read -r file; do\n            if [[ -f \"$file\" ]] &#x26;&#x26; [[ \"$file\" == */.github/workflows/* ]]; then\n                echo \"$file\" >> \"$TEMP_DIR/new_workflow_files.txt\"\n            fi\n        done &#x3C; \"$TEMP_DIR/formatter_workflows.txt\"\n    fi\n\n    # Look for actionsSecrets.json files (double Base64 encoded secrets)\n    # Use pre-categorized files from collect_all_files (performance optimization)\n    if [[ -s \"$TEMP_DIR/actions_secrets_found.txt\" ]]; then\n        while IFS= read -r file; do\n            if [[ -f \"$file\" ]]; then\n                echo \"$file\" >> \"$TEMP_DIR/actions_secrets_files.txt\"\n            fi\n        done &#x3C; \"$TEMP_DIR/actions_secrets_found.txt\"\n    fi\n}\n\n# Function: check_discussion_workflows\n# Purpose: Detect malicious GitHub Actions workflows with discussion triggers\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: $TEMP_DIR/discussion_workflows.txt (temp file)\n# Returns: Populates discussion_workflows.txt with paths to suspicious discussion-triggered workflows\ncheck_discussion_workflows() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for malicious discussion workflows...\"\n\n    # Phase 3 Optimization: Batch processing with combined patterns\n    # Create a temporary file list for valid workflow files to process in batches\n    while IFS= read -r file; do\n        [[ -f \"$file\" ]] &#x26;&#x26; echo \"$file\"\n    done &#x3C; \"$TEMP_DIR/github_workflows.txt\" > \"$TEMP_DIR/valid_workflows.txt\"\n\n    # Check if we have any files to process\n    if [[ ! -s \"$TEMP_DIR/valid_workflows.txt\" ]]; then\n        return 0\n    fi\n\n    # Batch 1: Discussion trigger patterns (combined for efficiency)\n    xargs -I {} grep -l -E \"on:.*discussion|on:\\s*discussion\" {} 2>/dev/null &#x3C; \"$TEMP_DIR/valid_workflows.txt\" | \\\n        while IFS= read -r file; do\n            echo \"$file:Discussion trigger detected\" >> \"$TEMP_DIR/discussion_workflows.txt\"\n        done || true\n\n    # Batch 2: Self-hosted runners with dynamic payloads (two-stage batch processing)\n    xargs -I {} grep -l \"runs-on:.*self-hosted\" {} 2>/dev/null &#x3C; \"$TEMP_DIR/valid_workflows.txt\" | \\\n        xargs -I {} grep -l \"\\${{ github\\.event\\..*\\.body }}\" {} 2>/dev/null | \\\n        while IFS= read -r file; do\n            echo \"$file:Self-hosted runner with dynamic payload execution\" >> \"$TEMP_DIR/discussion_workflows.txt\"\n        done || true\n\n    # Batch 3: Suspicious filenames (filename-based detection)\n    while IFS= read -r file; do\n        if [[ \"$(basename \"$file\")\" == \"discussion.yaml\" ]] || [[ \"$(basename \"$file\")\" == \"discussion.yml\" ]]; then\n            echo \"$file:Suspicious discussion workflow filename\" >> \"$TEMP_DIR/discussion_workflows.txt\"\n        fi\n    done &#x3C; \"$TEMP_DIR/valid_workflows.txt\"\n}\n\n# Function: check_github_runners\n# Purpose: Detect self-hosted GitHub Actions runners installed by malware\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: $TEMP_DIR/github_runners.txt (temp file)\n# Returns: Populates github_runners.txt with paths to suspicious runner installations\ncheck_github_runners() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for malicious GitHub Actions runners...\"\n\n    # Performance Optimization: Single find operation with combined patterns\n    {\n        # Use pre-collected suspicious directories if available\n        if [[ -f \"$TEMP_DIR/suspicious_dirs.txt\" ]]; then\n            cat \"$TEMP_DIR/suspicious_dirs.txt\"\n        fi\n\n        # Single find operation combining all patterns with timeout protection\n        timeout 10 find \"$scan_dir\" -type d \\( \\\n            -name \".dev-env\" -o \\\n            -name \"actions-runner\" -o \\\n            -name \".runner\" -o \\\n            -name \"_work\" \\\n        \\) 2>/dev/null || true\n    } | sort | uniq | while IFS= read -r dir; do\n        if [[ -d \"$dir\" ]]; then\n            # Check for runner configuration files\n            if [[ -f \"$dir/.runner\" ]] || [[ -f \"$dir/.credentials\" ]] || [[ -f \"$dir/config.sh\" ]]; then\n                echo \"$dir:Runner configuration files found\" >> \"$TEMP_DIR/github_runners.txt\"\n            fi\n\n            # Check for runner binaries\n            if [[ -f \"$dir/Runner.Worker\" ]] || [[ -f \"$dir/run.sh\" ]] || [[ -f \"$dir/run.cmd\" ]]; then\n                echo \"$dir:Runner executable files found\" >> \"$TEMP_DIR/github_runners.txt\"\n            fi\n\n            # Check for .dev-env specifically (from Koi.ai report)\n            if [[ \"$(basename \"$dir\")\" == \".dev-env\" ]]; then\n                echo \"$dir:Suspicious .dev-env directory (matches Koi.ai report)\" >> \"$TEMP_DIR/github_runners.txt\"\n            fi\n        fi\n    done\n\n    # Also check user home directory specifically for ~/.dev-env\n    if [[ -d \"${HOME}/.dev-env\" ]]; then\n        echo \"${HOME}/.dev-env:Malicious runner directory in home folder (Koi.ai IOC)\" >> \"$TEMP_DIR/github_runners.txt\"\n    fi\n}\n\n# Function: check_destructive_patterns\n# Purpose: Detect destructive patterns that can cause data loss when credential theft fails\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: $TEMP_DIR/destructive_patterns.txt (temp file)\n# Returns: Populates destructive_patterns.txt with paths to files containing destructive patterns\ncheck_destructive_patterns() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for destructive payload patterns...\"\n\n    # Phase 3 Optimization: Pre-compile combined regex patterns for batch processing\n    # Basic destructive patterns - ONLY flag when targeting user directories ($HOME, ~, /home/)\n    # Standalone rimraf/unlinkSync/rmSync removed to reduce false positives (GitHub issue #74)\n    local basic_destructive_regex=\"rm -rf[[:space:]]+(\\\\\\$HOME|~[^a-zA-Z0-9_/]|/home/)|del /s /q[[:space:]]+(%USERPROFILE%|\\\\\\$HOME)|Remove-Item -Recurse[[:space:]]+(\\\\\\$HOME|~[^a-zA-Z0-9_/])|find[[:space:]]+(\\\\\\$HOME|~[^a-zA-Z0-9_/]|/home/).*-exec rm|find[[:space:]]+(\\\\\\$HOME|~[^a-zA-Z0-9_/]|/home/).*-delete|\\\\\\$HOME/[*]|~/[*]|/home/[^/]+/[*]\"\n\n    # Conditional patterns for JavaScript/Python (limited span patterns)\n    # Note: exec.{1,30}rm limits span to avoid matching minified code where \"exec\" and \"rm\" are far apart\n    local js_py_conditional_regex=\"if.{1,200}credential.{1,50}(fail|error).{1,50}(rm -|fs\\.|rimraf|exec|spawn|child_process)|if.{1,200}token.{1,50}not.{1,20}found.{1,50}(rm -|del |fs\\.|rimraf|unlinkSync|rmSync)|if.{1,200}github.{1,50}auth.{1,50}fail.{1,50}(rm -|fs\\.|rimraf|exec)|catch.{1,100}(rm -rf|fs\\.rm|rimraf|exec.{1,30}rm)|error.{1,100}(rm -|del |fs\\.|rimraf).{1,100}(\\\\\\$HOME|~/|home.*(directory|folder|path))\"\n\n    # Shell-specific patterns (broader patterns for actual shell scripts)\n    local shell_conditional_regex=\"if.*credential.*(fail|error).*rm|if.*token.*not.*found.*(delete|rm)|if.*github.*auth.*fail.*rm|catch.*rm -rf|error.*delete.*home\"\n\n    # Phase 3 Optimization: Create file category lists for batch processing\n    cat \"$TEMP_DIR/script_files.txt\" \"$TEMP_DIR/code_files.txt\" 2>/dev/null | sort | uniq > \"$TEMP_DIR/all_script_files.txt\" || touch \"$TEMP_DIR/all_script_files.txt\"\n\n    # Separate files by type for optimized batch processing\n    grep -E '\\.(js|py)$' \"$TEMP_DIR/all_script_files.txt\" > \"$TEMP_DIR/js_py_files.txt\" 2>/dev/null || touch \"$TEMP_DIR/js_py_files.txt\"\n    grep -E '\\.(sh|bat|ps1|cmd)$' \"$TEMP_DIR/all_script_files.txt\" > \"$TEMP_DIR/shell_files.txt\" 2>/dev/null || touch \"$TEMP_DIR/shell_files.txt\"\n\n    # FAST: Use xargs without -I for bulk grep (much faster)\n    # Batch 1: Basic destructive patterns (all file types)\n    if [[ -s \"$TEMP_DIR/all_script_files.txt\" ]]; then\n        xargs grep -liE \"$basic_destructive_regex\" &#x3C; \"$TEMP_DIR/all_script_files.txt\" 2>/dev/null | \\\n            while IFS= read -r file; do\n                echo \"$file:Basic destructive pattern detected\" >> \"$TEMP_DIR/destructive_patterns.txt\"\n            done || true\n    fi\n\n    # Batch 2: JavaScript/Python conditional patterns\n    if [[ -s \"$TEMP_DIR/js_py_files.txt\" ]]; then\n        xargs grep -liE \"$js_py_conditional_regex\" &#x3C; \"$TEMP_DIR/js_py_files.txt\" 2>/dev/null | \\\n            while IFS= read -r file; do\n                echo \"$file:Conditional destruction pattern detected (JS/Python context)\" >> \"$TEMP_DIR/destructive_patterns.txt\"\n            done || true\n    fi\n\n    # Batch 3: Shell script conditional patterns\n    if [[ -s \"$TEMP_DIR/shell_files.txt\" ]]; then\n        xargs grep -liE \"$shell_conditional_regex\" &#x3C; \"$TEMP_DIR/shell_files.txt\" 2>/dev/null | \\\n            while IFS= read -r file; do\n                echo \"$file:Conditional destruction pattern detected (Shell script context)\" >> \"$TEMP_DIR/destructive_patterns.txt\"\n            done || true\n    fi\n}\n\n# Function: check_preinstall_bun_patterns\n# Purpose: Detect fake Bun runtime preinstall patterns in package.json files\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: PREINSTALL_BUN_PATTERNS (global array)\n# Returns: Populates array with files containing suspicious preinstall patterns\ncheck_preinstall_bun_patterns() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for fake Bun preinstall patterns...\"\n\n    # Look for package.json files with suspicious \"preinstall\": \"node setup_bun.js\" pattern\n    while IFS= read -r file; do\n        if [[ -f \"$file\" ]]; then\n            # Check if the file contains the malicious preinstall pattern\n            if grep -q '\"preinstall\"[[:space:]]*:[[:space:]]*\"node setup_bun\\.js\"' \"$file\" 2>/dev/null; then\n                echo \"$file\" >> \"$TEMP_DIR/preinstall_bun_patterns.txt\"\n            fi\n        fi\n    # Use pre-categorized files from collect_all_files (performance optimization)\n    done &#x3C; \"$TEMP_DIR/package_files.txt\"\n}\n\n# Function: check_github_actions_runner\n# Purpose: Detect SHA1HULUD GitHub Actions runners in workflow files\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: GITHUB_SHA1HULUD_RUNNERS (global array)\n# Returns: Populates array with workflow files containing SHA1HULUD runner references\ncheck_github_actions_runner() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for SHA1HULUD GitHub Actions runners...\"\n\n    # Look for workflow files containing SHA1HULUD runner names\n    while IFS= read -r file; do\n        if [[ -f \"$file\" ]]; then\n            # Check for SHA1HULUD runner references in YAML files\n            if grep -qi \"SHA1HULUD\" \"$file\" 2>/dev/null; then\n                echo \"$file\" >> \"$TEMP_DIR/github_sha1hulud_runners.txt\"\n            fi\n        fi\n    # Use pre-categorized files from collect_all_files (performance optimization)\n    done &#x3C; \"$TEMP_DIR/yaml_files.txt\"\n}\n\n# Function: check_second_coming_repos\n# Purpose: Detect repository descriptions with \"Sha1-Hulud: The Second Coming\" pattern\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: SECOND_COMING_REPOS (global array)\n# Returns: Populates array with git repositories matching the description pattern\ncheck_second_coming_repos() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for 'Second Coming' repository descriptions...\"\n\n    # Performance Optimization: Use pre-collected git repositories\n    local git_repos_source\n    if [[ -f \"$TEMP_DIR/git_repos.txt\" ]]; then\n        git_repos_source=\"$TEMP_DIR/git_repos.txt\"\n    else\n        # Fallback with timeout protection\n        timeout 10 find \"$scan_dir\" -type d -name \".git\" 2>/dev/null | sed 's|/.git$||' > \"$TEMP_DIR/git_repos_fallback.txt\" || true\n        git_repos_source=\"$TEMP_DIR/git_repos_fallback.txt\"\n    fi\n\n    # Check git repositories with malicious descriptions\n    while IFS= read -r repo_dir; do\n        if [[ -d \"$repo_dir/.git\" ]]; then\n            # Check git config for repository description with timeout\n            local description\n            if command -v timeout >/dev/null 2>&#x26;1; then\n                # GNU timeout is available\n                if description=$(timeout 5s git -C \"$repo_dir\" config --get --local --null --default \"\" repository.description 2>/dev/null | tr -d '\\0'); then\n                    if [[ \"$description\" == *\"Sha1-Hulud: The Second Coming\"* ]]; then\n                        echo \"$repo_dir\" >> \"$TEMP_DIR/second_coming_repos.txt\"\n                    fi\n                fi\n            else\n                # Fallback for systems without timeout command (e.g., macOS)\n                if description=$(git -C \"$repo_dir\" config --get --local --null --default \"\" repository.description 2>/dev/null | tr -d '\\0'); then\n                    if [[ \"$description\" == *\"Sha1-Hulud: The Second Coming\"* ]]; then\n                        echo \"$repo_dir\" >> \"$TEMP_DIR/second_coming_repos.txt\"\n                    fi\n                fi\n            fi\n            # Skip repositories where git command times out or fails\n        fi\n    done &#x3C; \"$git_repos_source\"\n}\n\n# Function: check_file_hashes\n# Purpose: Scan files and compare SHA256 hashes against known malicious hash list\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: MALICIOUS_HASHES (global array)\n# Returns: Populates MALICIOUS_HASHES array with \"file:hash\" entries for matches\ncheck_file_hashes() {\n    local scan_dir=$1\n    local totalFiles\n    totalFiles=$(wc -l &#x3C; \"$TEMP_DIR/code_files.txt\" 2>/dev/null || echo \"0\")\n\n    # FAST FILTER: Use single find command for recently modified non-node_modules files\n    # This is much faster than looping through every file with stat\n    print_status \"$BLUE\" \"   Filtering files for hash checking...\"\n\n    # Priority files: recently modified (30 days) OR known malicious patterns\n    {\n        # Priority 1: Known malicious file patterns (always check)\n        grep -E \"(setup_bun\\.js|bun_environment\\.js|actionsSecrets\\.json|trufflehog)\" \"$TEMP_DIR/code_files.txt\" 2>/dev/null || true\n\n        # Priority 2: Non-node_modules files (fast grep filter)\n        grep -v \"/node_modules/\" \"$TEMP_DIR/code_files.txt\" 2>/dev/null || true\n    } | sort | uniq > \"$TEMP_DIR/priority_files.txt\"\n\n    local filesCount\n    filesCount=$(wc -l &#x3C; \"$TEMP_DIR/priority_files.txt\" 2>/dev/null || echo \"0\")\n\n    print_status \"$BLUE\" \"   Checking $filesCount priority files for known malicious content (filtered from $totalFiles total)...\"\n\n    # BATCH HASH: Calculate all hashes in parallel using xargs\n    # Create hash lookup file with format: hash filename\n    print_status \"$BLUE\" \"   Computing hashes in parallel...\"\n    # FIX: Use sha256sum on Linux/WSL, shasum on macOS/Git Bash\n    # Check if shasum actually works (not just exists in PATH)\n    local hash_cmd=\"sha256sum\"\n    if shasum -a 256 /dev/null &#x26;>/dev/null; then\n        hash_cmd=\"shasum -a 256\"\n    fi\n    xargs -P \"$PARALLELISM\" $hash_cmd &#x3C; \"$TEMP_DIR/priority_files.txt\" 2>/dev/null | \\\n        awk '{print $1, $2}' > \"$TEMP_DIR/file_hashes.txt\"\n\n    # Create malicious hash lookup pattern for grep\n    printf '%s\\n' \"${MALICIOUS_HASHLIST[@]}\" > \"$TEMP_DIR/malicious_patterns.txt\"\n\n    # Fast set intersection: find matching hashes\n    print_status \"$BLUE\" \"   Checking against known malicious hashes...\"\n    while IFS=' ' read -r hash file; do\n        if grep -qF \"$hash\" \"$TEMP_DIR/malicious_patterns.txt\" 2>/dev/null; then\n            echo \"$file:$hash\" >> \"$TEMP_DIR/malicious_hashes.txt\"\n        fi\n    done &#x3C; \"$TEMP_DIR/file_hashes.txt\"\n}\n\n# Function: transform_pnpm_yaml\n# Purpose: Convert pnpm-lock.yaml to pseudo-package-lock.json format for parsing\n# Args: $1 = packages_file (path to pnpm-lock.yaml)\n# Modifies: None\n# Returns: Outputs JSON to stdout with packages structure compatible with package-lock parser\ntransform_pnpm_yaml() {\n    declare -a path\n    packages_file=$1\n\n    echo -e \"{\"\n    echo -e \"  \\\"packages\\\": {\"\n\n    depth=0\n    while IFS= read -r line; do\n\n        # Find indentation\n        sep=\"${line%%[^ ]*}\"\n        currentdepth=\"${#sep}\"\n\n        # Remove surrounding whitespace\n        line=${line##*( )} # From the beginning\n        line=${line%%*( )} # From the end\n\n        # Remove comments\n        line=${line%%#*}\n        line=${line%%*( )}\n\n        # Remove comments and empty lines\n        if [[ \"${line:0:1}\" == '#' ]] || [[ \"${#line}\" == 0 ]]; then\n            continue\n        fi\n\n        # split into key/val\n        key=${line%%:*}\n        key=${key%%*( )}\n        val=${line#*:}\n        val=${val##*( )}\n\n        # Save current path\n        path[$currentdepth]=$key\n\n        # Interested in packages.*\n        if [ \"${path[0]}\" != \"packages\" ]; then continue; fi\n        if [ \"${currentdepth}\" != \"2\" ]; then continue; fi\n\n        # Remove surrounding whitespace (yes, again)\n        key=\"${key#\"${key%%[![:space:]]*}\"}\"\n        key=\"${key%\"${key##*[![:space:]]}\"}\"\n\n        # Remove quote\n        key=\"${key#\"${key%%[!\\']*}\"}\"\n        key=\"${key%\"${key##*[!\\']}\"}\"\n\n        # split into name/version\n        name=${key%\\@*}\n        name=${name%*( )}\n        version=${key##*@}\n        version=${version##*( )}\n\n        echo \"    \\\"${name}\\\": {\"\n        echo \"      \\\"version\\\": \\\"${version}\\\"\"\n        echo \"    },\"\n\n    done &#x3C; \"$packages_file\"\n    echo \"  }\"\n    echo \"}\"\n}\n\n# Function: semverParseInto\n# Purpose: Parse semantic version string into major, minor, patch, and special components\n# Args: $1 = version_string, $2 = major_var, $3 = minor_var, $4 = patch_var, $5 = special_var\n# Modifies: Sets variables named by $2-$5 using printf -v\n# Returns: Populates variables with parsed version components\n# Origin: https://github.com/cloudflare/semver_bash/blob/6cc9ce10/semver.sh\nsemverParseInto() {\n  local RE='[^0-9]*\\([0-9]*\\)[.]\\([0-9]*\\)[.]\\([0-9]*\\)\\([0-9A-Za-z-]*\\)'\n  #MAJOR\n  printf -v \"$2\" '%s' \"$(echo $1 | sed -e \"s/$RE/\\1/\")\"\n  #MINOR\n  printf -v \"$3\" '%s' \"$(echo $1 | sed -e \"s/$RE/\\2/\")\"\n  #PATCH\n  printf -v \"$4\" '%s' \"$(echo $1 | sed -e \"s/$RE/\\3/\")\"\n  #SPECIAL\n  printf -v \"$5\" '%s' \"$(echo $1 | sed -e \"s/$RE/\\4/\")\"\n}\n\n# Function: semver_match\n# Purpose: Check if version matches semver pattern with caret (^), tilde (~), or exact matching\n# Args: $1 = test_subject (version to test), $2 = test_pattern (pattern like \"^1.0.0\" or \"~1.1.0\")\n# Modifies: None\n# Returns: 0 for match, 1 for no match (supports || for multi-pattern matching)\n# Examples: \"1.1.2\" matches \"^1.0.0\", \"~1.1.0\", \"*\" but not \"^2.0.0\" or \"~1.2.0\"\nsemver_match() {\n    local test_subject=$1\n    local test_pattern=$2\n\n    # Always matches\n    if [[ \"*\" == \"${test_pattern}\" ]]; then\n        return 0\n    fi\n\n    # Destructure subject\n    local subject_major=0\n    local subject_minor=0\n    local subject_patch=0\n    local subject_special=0\n    semverParseInto ${test_subject} subject_major subject_minor subject_patch subject_special\n\n    # Handle multi-variant patterns\n    while IFS= read -r pattern; do\n        pattern=\"${pattern#\"${pattern%%[![:space:]]*}\"}\"\n        pattern=\"${pattern%\"${pattern##*[![:space:]]}\"}\"\n        # Always matches\n        if [[ \"*\" == \"${pattern}\" ]]; then\n            return 0\n        fi\n        local pattern_major=0\n        local pattern_minor=0\n        local pattern_patch=0\n        local pattern_special=0\n        case \"${pattern}\" in\n            ^*) # Major must match\n                semverParseInto ${pattern:1} pattern_major pattern_minor pattern_patch pattern_special\n                [[ \"${subject_major}\"  ==  \"${pattern_major}\"   ]] || continue\n                [[ \"${subject_minor}\" -ge  \"${pattern_minor}\"   ]] || continue\n                if [[ \"${subject_minor}\" == \"${pattern_minor}\"   ]]; then\n                    [[ \"${subject_patch}\"   -ge \"${pattern_patch}\"   ]] || continue\n                fi\n                return 0 # Match\n                ;;\n            ~*) # Major+minor must match\n                semverParseInto ${pattern:1} pattern_major pattern_minor pattern_patch pattern_special\n                [[ \"${subject_major}\"   ==  \"${pattern_major}\"   ]] || continue\n                [[ \"${subject_minor}\"   ==  \"${pattern_minor}\"   ]] || continue\n                [[ \"${subject_patch}\"   -ge \"${pattern_patch}\"   ]] || continue\n                return 0 # Match\n                ;;\n            *[xX]*) # Wildcard pattern (4.x, 1.2.x, 4.X, 1.2.X, etc.)\n                # Parse pattern components, handling 'x' wildcards specially\n                local pattern_parts\n                IFS='.' read -ra pattern_parts &#x3C;&#x3C;&#x3C; \"${pattern}\"\n                local subject_parts\n                IFS='.' read -ra subject_parts &#x3C;&#x3C;&#x3C; \"${test_subject}\"\n\n                # Check each component, skip comparison for 'x' wildcards\n                for i in 0 1 2; do\n                    if [[ ${i} -lt ${#pattern_parts[@]} &#x26;&#x26; ${i} -lt ${#subject_parts[@]} ]]; then\n                        local pattern_part=\"${pattern_parts[i]}\"\n                        local subject_part=\"${subject_parts[i]}\"\n\n                        # Skip wildcard components (both lowercase x and uppercase X)\n                        if [[ \"${pattern_part}\" == \"x\" ]] || [[ \"${pattern_part}\" == \"X\" ]]; then\n                            continue\n                        fi\n\n                        # Extract numeric part (remove any non-numeric suffix)\n                        pattern_part=$(echo \"${pattern_part}\" | sed 's/[^0-9].*//')\n                        subject_part=$(echo \"${subject_part}\" | sed 's/[^0-9].*//')\n\n                        # Compare numeric parts\n                        if [[ \"${subject_part}\" != \"${pattern_part}\" ]]; then\n                            continue 2  # Continue outer loop (try next pattern)\n                        fi\n                    fi\n                done\n                return 0 # Match\n                ;;\n            *) # Exact match\n                semverParseInto ${pattern} pattern_major pattern_minor pattern_patch pattern_special\n                [[ \"${subject_major}\"  -eq \"${pattern_major}\"   ]] || continue\n                [[ \"${subject_minor}\"  -eq \"${pattern_minor}\"   ]] || continue\n                [[ \"${subject_patch}\"  -eq \"${pattern_patch}\"   ]] || continue\n                [[ \"${subject_special}\" == \"${pattern_special}\" ]] || continue\n                return 0 # MATCH\n                ;;\n        esac\n        # Splits '||' into newlines with sed\n    done &#x3C; &#x3C;(echo \"${test_pattern}\" | sed 's/||/\\n/g')\n\n    # Fallthrough = no match\n    return 1;\n}\n\n# Function: check_packages\n# Purpose: Scan package.json files for compromised packages and suspicious namespaces\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: COMPROMISED_FOUND, SUSPICIOUS_FOUND, NAMESPACE_WARNINGS (global arrays)\n# Returns: Populates arrays with matches using exact and semver pattern matching\ncheck_packages() {\n    local scan_dir=$1\n\n    local filesCount\n    filesCount=$(wc -l &#x3C; \"$TEMP_DIR/package_files.txt\" 2>/dev/null || echo \"0\")\n\n    print_status \"$BLUE\" \"   Checking $filesCount package.json files for compromised packages...\"\n\n    # BATCH OPTIMIZATION: Extract all deps using parallel processing\n    print_status \"$BLUE\" \"   Extracting dependencies from all package.json files...\"\n\n    # Create optimized lookup table from compromised packages (sorted for join)\n    awk -F: '{print $1\":\"$2}' $SCRIPT_DIR/compromised-packages.txt | LC_ALL=C sort > \"$TEMP_DIR/compromised_lookup.txt\"\n\n    # Extract all dependencies from all package.json files using parallel xargs + awk\n    # Format: file_path|package_name:version\n    # Use awk to parse JSON dependencies - portable and fast\n    xargs -P \"$PARALLELISM\" -I {} awk -v file=\"{}\" '\n        /\"dependencies\":|\"devDependencies\":/ {flag=1; next}\n        /^[[:space:]]*\\}/ {flag=0}\n        flag &#x26;&#x26; /^[[:space:]]*\"[^\"]+\":/ {\n            # Extract \"package\": \"version\"\n            gsub(/^[[:space:]]*\"/, \"\")\n            gsub(/\":[[:space:]]*\"/, \":\")\n            gsub(/\".*$/, \"\")\n            if (length($0) > 0 &#x26;&#x26; index($0, \":\") > 0) {\n                print file \"|\" $0\n            }\n        }\n    ' {} &#x3C; \"$TEMP_DIR/package_files.txt\" > \"$TEMP_DIR/all_deps.txt\" 2>/dev/null\n\n    # FAST SET INTERSECTION: Use awk hash lookup instead of grep per line\n    print_status \"$BLUE\" \"   Checking dependencies against compromised list...\"\n    local depCount=$(wc -l &#x3C; \"$TEMP_DIR/all_deps.txt\" 2>/dev/null || echo \"0\")\n    print_status \"$BLUE\" \"   Found $depCount total dependencies to check\"\n\n    # Create sorted deps file for set intersection\n    cut -d'|' -f2 \"$TEMP_DIR/all_deps.txt\" | LC_ALL=C sort | uniq > \"$TEMP_DIR/deps_only.txt\"\n\n    # Find matching deps using comm (set intersection - super fast)\n    # FIX: Use LC_ALL=C to ensure comm uses the same sort order as sort (Git Bash compatibility)\n    LC_ALL=C comm -12 \"$TEMP_DIR/compromised_lookup.txt\" \"$TEMP_DIR/deps_only.txt\" > \"$TEMP_DIR/matched_deps.txt\"\n\n    # If matches found, map back to file paths\n    if [[ -s \"$TEMP_DIR/matched_deps.txt\" ]]; then\n        while IFS= read -r matched_dep; do\n            { grep -F \"|$matched_dep\" \"$TEMP_DIR/all_deps.txt\" || true; } | while IFS='|' read -r file_path dep; do\n                [[ -n \"$file_path\" ]] &#x26;&#x26; echo \"$file_path:${dep/:/@}\" >> \"$TEMP_DIR/compromised_found.txt\"\n            done\n        done &#x3C; \"$TEMP_DIR/matched_deps.txt\"\n    fi\n\n    # Check for suspicious namespaces - simplified for speed\n    print_status \"$BLUE\" \"   Checking for compromised namespaces...\"\n    # Quick check: just look in the already-extracted dependencies file\n    # This is much faster than re-reading all package.json files\n    for namespace in \"${COMPROMISED_NAMESPACES[@]}\"; do\n        # Check if any dependency starts with this namespace\n        if grep -q \"|$namespace/\" \"$TEMP_DIR/all_deps.txt\" 2>/dev/null; then\n            { grep \"|$namespace/\" \"$TEMP_DIR/all_deps.txt\" || true; } | cut -d'|' -f1 | sort | uniq | while read -r file; do\n                [[ -n \"$file\" ]] &#x26;&#x26; echo \"$file:Contains packages from compromised namespace: $namespace\" >> \"$TEMP_DIR/namespace_warnings.txt\"\n            done\n        fi\n    done\n\n    echo -ne \"\\r\\033[K\"\n}\n\n# Function: check_postinstall_hooks\n# Purpose: Detect suspicious postinstall scripts that may execute malicious code\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: POSTINSTALL_HOOKS (global array)\n# Returns: Populates POSTINSTALL_HOOKS array with package.json files containing hooks\ncheck_postinstall_hooks() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for suspicious postinstall hooks...\"\n\n    while IFS= read -r -d '' package_file; do\n        if [[ -f \"$package_file\" &#x26;&#x26; -r \"$package_file\" ]]; then\n            # Look for postinstall scripts\n            if grep -q \"\\\"postinstall\\\"\" \"$package_file\" 2>/dev/null; then\n                local postinstall_cmd\n                postinstall_cmd=$(grep -A1 \"\\\"postinstall\\\"\" \"$package_file\" 2>/dev/null | grep -o '\"[^\"]*\"' 2>/dev/null | tail -1 2>/dev/null | tr -d '\"' 2>/dev/null || true) || true\n\n                # Check for suspicious patterns in postinstall commands\n                if [[ -n \"$postinstall_cmd\" ]] &#x26;&#x26; ([[ \"$postinstall_cmd\" == *\"curl\"* ]] || [[ \"$postinstall_cmd\" == *\"wget\"* ]] || [[ \"$postinstall_cmd\" == *\"node -e\"* ]] || [[ \"$postinstall_cmd\" == *\"eval\"* ]]); then\n                    echo \"$package_file:Suspicious postinstall: $postinstall_cmd\" >> \"$TEMP_DIR/postinstall_hooks.txt\"\n                fi\n            fi\n        fi\n    # Use pre-categorized files from collect_all_files (performance optimization)\n    done &#x3C; &#x3C;(tr '\\n' '\\0' &#x3C; \"$TEMP_DIR/package_files.txt\")\n}\n\n# Function: check_content\n# Purpose: Search for suspicious content patterns like webhook.site and malicious endpoints\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: SUSPICIOUS_CONTENT (global array)\n# Returns: Populates SUSPICIOUS_CONTENT array with files containing suspicious patterns\ncheck_content() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for suspicious content patterns...\"\n\n    # FAST: Use xargs with grep -l for bulk searching instead of per-file grep\n    # Search for webhook.site references\n    {\n        xargs grep -l \"webhook\\.site\" &#x3C; &#x3C;(cat \"$TEMP_DIR/code_files.txt\" \"$TEMP_DIR/yaml_files.txt\" 2>/dev/null) 2>/dev/null || true\n    } | while read -r file; do\n        [[ -n \"$file\" ]] &#x26;&#x26; echo \"$file:webhook.site reference\" >> \"$TEMP_DIR/suspicious_content.txt\"\n    done\n\n    # Search for malicious webhook endpoint\n    {\n        xargs grep -l \"bb8ca5f6-4175-45d2-b042-fc9ebb8170b7\" &#x3C; &#x3C;(cat \"$TEMP_DIR/code_files.txt\" \"$TEMP_DIR/yaml_files.txt\" 2>/dev/null) 2>/dev/null || true\n    } | while read -r file; do\n        [[ -n \"$file\" ]] &#x26;&#x26; echo \"$file:malicious webhook endpoint\" >> \"$TEMP_DIR/suspicious_content.txt\"\n    done\n}\n\n# Function: check_crypto_theft_patterns\n# Purpose: Detect cryptocurrency theft patterns from the Chalk/Debug attack (Sept 8, 2025)\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: CRYPTO_PATTERNS, HIGH_RISK_CRYPTO (global arrays)\n# Returns: Populates arrays with wallet hijacking, XMLHttpRequest tampering, and attacker indicators\ncheck_crypto_theft_patterns() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for cryptocurrency theft patterns...\"\n\n    # FAST: Use xargs with grep -l for bulk pattern searching\n    # Check for specific malicious functions from chalk/debug attack (highest priority)\n    {\n        xargs grep -lE \"checkethereumw|runmask|newdlocal|_0x19ca67\" &#x3C; \"$TEMP_DIR/code_files.txt\" 2>/dev/null || true\n    } | while read -r file; do\n        [[ -n \"$file\" ]] &#x26;&#x26; echo \"$file:Known crypto theft function names detected\" >> \"$TEMP_DIR/crypto_patterns.txt\"\n    done\n\n    # Check for known attacker wallets (high priority)\n    {\n        xargs grep -lE \"0xFc4a4858bafef54D1b1d7697bfb5c52F4c166976|1H13VnQJKtT4HjD5ZFKaaiZEetMbG7nDHx|TB9emsCq6fQw6wRk4HBxxNnU6Hwt1DnV67\" &#x3C; \"$TEMP_DIR/code_files.txt\" 2>/dev/null || true\n    } | while read -r file; do\n        [[ -n \"$file\" ]] &#x26;&#x26; echo \"$file:Known attacker wallet address detected - HIGH RISK\" >> \"$TEMP_DIR/crypto_patterns.txt\"\n    done\n\n    # Check for npmjs.help phishing domain\n    {\n        xargs grep -l \"npmjs\\.help\" &#x3C; \"$TEMP_DIR/code_files.txt\" 2>/dev/null || true\n    } | while read -r file; do\n        [[ -n \"$file\" ]] &#x26;&#x26; echo \"$file:Phishing domain npmjs.help detected\" >> \"$TEMP_DIR/crypto_patterns.txt\"\n    done\n\n    # Check for XMLHttpRequest hijacking (medium priority - filter out framework code)\n    {\n        xargs grep -l \"XMLHttpRequest\\.prototype\\.send\" &#x3C; \"$TEMP_DIR/code_files.txt\" 2>/dev/null || true\n    } | while read -r file; do\n        [[ -z \"$file\" ]] &#x26;&#x26; continue\n        if [[ \"$file\" == *\"/react-native/Libraries/Network/\"* ]] || [[ \"$file\" == *\"/next/dist/compiled/\"* ]]; then\n            # Framework code - check for crypto patterns too\n            if grep -qE \"0x[a-fA-F0-9]{40}|checkethereumw|runmask|webhook\\.site|npmjs\\.help\" \"$file\" 2>/dev/null; then\n                echo \"$file:XMLHttpRequest prototype modification with crypto patterns detected - HIGH RISK\" >> \"$TEMP_DIR/crypto_patterns.txt\"\n            else\n                echo \"$file:XMLHttpRequest prototype modification detected in framework code - LOW RISK\" >> \"$TEMP_DIR/crypto_patterns.txt\"\n            fi\n        else\n            if grep -qE \"0x[a-fA-F0-9]{40}|checkethereumw|runmask|webhook\\.site|npmjs\\.help\" \"$file\" 2>/dev/null; then\n                echo \"$file:XMLHttpRequest prototype modification with crypto patterns detected - HIGH RISK\" >> \"$TEMP_DIR/crypto_patterns.txt\"\n            else\n                echo \"$file:XMLHttpRequest prototype modification detected - MEDIUM RISK\" >> \"$TEMP_DIR/crypto_patterns.txt\"\n            fi\n        fi\n    done\n\n    # Check for javascript obfuscation\n    {\n        xargs grep -l \"javascript-obfuscator\" &#x3C; \"$TEMP_DIR/code_files.txt\" 2>/dev/null || true\n    } | while read -r file; do\n        [[ -n \"$file\" ]] &#x26;&#x26; echo \"$file:JavaScript obfuscation detected\" >> \"$TEMP_DIR/crypto_patterns.txt\"\n    done\n\n    # Check for generic Ethereum wallet address patterns (MEDIUM priority)\n    # Files with 0x addresses AND crypto-related keywords\n    {\n        xargs grep -lE \"0x[a-fA-F0-9]{40}\" &#x3C; \"$TEMP_DIR/code_files.txt\" 2>/dev/null || true\n    } | while read -r file; do\n        [[ -z \"$file\" ]] &#x26;&#x26; continue\n        # Skip if already flagged as HIGH RISK\n        if grep -qF \"$file:\" \"$TEMP_DIR/crypto_patterns.txt\" 2>/dev/null; then\n            continue\n        fi\n        # Check for crypto-related context keywords\n        if grep -qE \"ethereum|wallet|address|crypto\" \"$file\" 2>/dev/null; then\n            echo \"$file:Ethereum wallet address patterns detected\" >> \"$TEMP_DIR/crypto_patterns.txt\"\n        fi\n    done\n}\n\n# Function: check_git_branches\n# Purpose: Search for suspicious git branches containing \"shai-hulud\" in their names\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: GIT_BRANCHES (global array)\n# Returns: Populates GIT_BRANCHES array with branch names and commit hashes\ncheck_git_branches() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for suspicious git branches...\"\n\n    # Performance Optimization: Use pre-collected git repositories and limit search scope\n    if [[ -f \"$TEMP_DIR/git_repos.txt\" ]]; then\n        while IFS= read -r repo_dir; do\n            if [[ -d \"$repo_dir/.git/refs/heads\" ]]; then\n                # Quick check: only look for shai-hulud patterns in branch names\n                local git_refs_dir=\"$repo_dir/.git/refs/heads\"\n                if [[ -d \"$git_refs_dir\" ]]; then\n                    # Use shell globbing instead of find for better performance\n                    for branch_file in \"$git_refs_dir\"/*shai-hulud* \"$git_refs_dir\"/*shai*hulud*; do\n                        if [[ -f \"$branch_file\" ]]; then\n                            local branch_name\n                            branch_name=$(basename \"$branch_file\")\n                            local commit_hash\n                            commit_hash=$(cat \"$branch_file\" 2>/dev/null || echo \"unknown\")\n                            echo \"$repo_dir:Branch '$branch_name' (commit: ${commit_hash:0:8}...)\" >> \"$TEMP_DIR/git_branches.txt\"\n                        fi\n                    done\n                fi\n            fi\n        done &#x3C; \"$TEMP_DIR/git_repos.txt\"\n    else\n        # Fallback: quick search with timeout to prevent hanging\n        timeout 5 find \"$scan_dir\" -name \".git\" -type d 2>/dev/null | head -20 | while IFS= read -r git_dir; do\n            local repo_dir\n            repo_dir=$(dirname \"$git_dir\")\n            if [[ -d \"$git_dir/refs/heads\" ]]; then\n                # Quick check only\n                for branch_file in \"$git_dir/refs/heads\"/*shai-hulud*; do\n                    if [[ -f \"$branch_file\" ]]; then\n                        local branch_name\n                        branch_name=$(basename \"$branch_file\")\n                        echo \"$repo_dir:Branch '$branch_name'\" >> \"$TEMP_DIR/git_branches.txt\"\n                    fi\n                done\n            fi\n        done || true  # Don't fail if timeout occurs\n    fi\n}\n\n# Function: get_file_context\n# Purpose: Classify file context for risk assessment (node_modules, source, build, etc.)\n# Args: $1 = file_path (path to file)\n# Modifies: None\n# Returns: Echoes context string (node_modules, documentation, type_definitions, build_output, configuration, source_code)\nget_file_context() {\n    local file_path=$1\n\n    # Check if file is in node_modules\n    if [[ \"$file_path\" == *\"/node_modules/\"* ]]; then\n        echo \"node_modules\"\n        return\n    fi\n\n    # Check if file is documentation\n    if [[ \"$file_path\" == *\".md\" ]] || [[ \"$file_path\" == *\".txt\" ]] || [[ \"$file_path\" == *\".rst\" ]]; then\n        echo \"documentation\"\n        return\n    fi\n\n    # Check if file is TypeScript definitions\n    if [[ \"$file_path\" == *\".d.ts\" ]]; then\n        echo \"type_definitions\"\n        return\n    fi\n\n    # Check if file is in build/dist directories\n    if [[ \"$file_path\" == *\"/dist/\"* ]] || [[ \"$file_path\" == *\"/build/\"* ]] || [[ \"$file_path\" == *\"/public/\"* ]]; then\n        echo \"build_output\"\n        return\n    fi\n\n    # Check if it's a config file\n    if [[ \"$(basename \"$file_path\")\" == *\"config\"* ]] || [[ \"$(basename \"$file_path\")\" == *\".config.\"* ]]; then\n        echo \"configuration\"\n        return\n    fi\n\n    echo \"source_code\"\n}\n\n# Function: is_legitimate_pattern\n# Purpose: Identify legitimate framework/build tool patterns to reduce false positives\n# Args: $1 = file_path, $2 = content_sample (text snippet from file)\n# Modifies: None\n# Returns: 0 for legitimate, 1 for potentially suspicious\nis_legitimate_pattern() {\n    local file_path=$1\n    local content_sample=\"$2\"\n\n    # Vue.js development patterns\n    if [[ \"$content_sample\" == *\"process.env.NODE_ENV\"* ]] &#x26;&#x26; [[ \"$content_sample\" == *\"production\"* ]]; then\n        return 0  # legitimate\n    fi\n\n    # Common framework patterns\n    if [[ \"$content_sample\" == *\"createApp\"* ]] || [[ \"$content_sample\" == *\"Vue\"* ]]; then\n        return 0  # legitimate\n    fi\n\n    # Package manager and build tool patterns\n    if [[ \"$content_sample\" == *\"webpack\"* ]] || [[ \"$content_sample\" == *\"vite\"* ]] || [[ \"$content_sample\" == *\"rollup\"* ]]; then\n        return 0  # legitimate\n    fi\n\n    return 1  # potentially suspicious\n}\n\n# Function: get_lockfile_version\n# Purpose: Extract actual installed version from lockfile for a specific package\n# Args: $1 = package_name, $2 = package_json_dir (directory containing package.json), $3 = scan_boundary (original scan directory)\n# Modifies: None\n# Returns: Echoes installed version or empty string if not found\nget_lockfile_version() {\n    local package_name=\"$1\"\n    local package_dir=\"$2\"\n    local scan_boundary=\"$3\"\n\n    # Search upward for lockfiles (supports packages in node_modules subdirectories)\n    local current_dir=\"$package_dir\"\n\n    # Traverse up the directory tree until we find a lockfile, reach root, or hit scan boundary\n    while [[ \"$current_dir\" != \"/\" &#x26;&#x26; \"$current_dir\" != \".\" &#x26;&#x26; -n \"$current_dir\" ]]; do\n        # SECURITY: Don't search above the original scan directory boundary\n        if [[ ! \"$current_dir/\" =~ ^\"$scan_boundary\"/ &#x26;&#x26; \"$current_dir\" != \"$scan_boundary\" ]]; then\n            break\n        fi\n        # Check for package-lock.json first (most common)\n        if [[ -f \"$current_dir/package-lock.json\" ]]; then\n            # Use the existing logic from check_package_integrity for block-based parsing\n            local found_version\n            found_version=$(awk -v pkg=\"node_modules/$package_name\" '\n                $0 ~ \"\\\"\" pkg \"\\\":\" { in_block=1; brace_count=1 }\n                in_block &#x26;&#x26; /\\{/ &#x26;&#x26; !($0 ~ \"\\\"\" pkg \"\\\":\") { brace_count++ }\n                in_block &#x26;&#x26; /\\}/ {\n                    brace_count--\n                    if (brace_count &#x3C;= 0) { in_block=0 }\n                }\n                in_block &#x26;&#x26; /\\s*\"version\":/ {\n                    # Extract version value between quotes\n                    split($0, parts, \"\\\"\")\n                    for (i in parts) {\n                        if (parts[i] ~ /^[0-9]/) {\n                            print parts[i]\n                            exit\n                        }\n                    }\n                }\n            ' \"$current_dir/package-lock.json\" 2>/dev/null || true)\n\n            if [[ -n \"$found_version\" ]]; then\n                echo \"$found_version\"\n                return\n            fi\n        fi\n\n        # Check for yarn.lock\n        if [[ -f \"$current_dir/yarn.lock\" ]]; then\n            # Yarn.lock format: package-name@version:\n            local found_version\n            found_version=$(grep \"^\\\"\\\\?$package_name@\" \"$current_dir/yarn.lock\" 2>/dev/null | head -1 | sed 's/.*@\\([^\"]*\\).*/\\1/' 2>/dev/null || true)\n            if [[ -n \"$found_version\" ]]; then\n                echo \"$found_version\"\n                return\n            fi\n        fi\n\n        # Check for pnpm-lock.yaml\n        if [[ -f \"$current_dir/pnpm-lock.yaml\" ]]; then\n            # Use transform_pnpm_yaml and then parse like package-lock.json\n            local temp_lockfile\n            temp_lockfile=$(mktemp \"${TMPDIR:-/tmp}/pnpm-parse.XXXXXXXX\")\n            TEMP_FILES+=(\"$temp_lockfile\")\n\n            transform_pnpm_yaml \"$current_dir/pnpm-lock.yaml\" > \"$temp_lockfile\" 2>/dev/null\n\n            local found_version\n            found_version=$(awk -v pkg=\"$package_name\" '\n                $0 ~ \"\\\"\" pkg \"\\\"\" { in_block=1; brace_count=1 }\n                in_block &#x26;&#x26; /\\{/ &#x26;&#x26; !($0 ~ \"\\\"\" pkg \"\\\"\") { brace_count++ }\n                in_block &#x26;&#x26; /\\}/ {\n                    brace_count--\n                    if (brace_count &#x3C;= 0) { in_block=0 }\n                }\n                in_block &#x26;&#x26; /\\s*\"version\":/ {\n                    gsub(/.*\"version\":\\s*\"/, \"\")\n                    gsub(/\".*/, \"\")\n                    print $0\n                    exit\n                }\n            ' \"$temp_lockfile\" 2>/dev/null || true)\n\n            if [[ -n \"$found_version\" ]]; then\n                echo \"$found_version\"\n                return\n            fi\n        fi\n\n        # Move to parent directory\n        current_dir=$(dirname \"$current_dir\")\n    done\n\n    # No lockfile or package not found\n    echo \"\"\n}\n\n# Function: check_trufflehog_activity\n# Purpose: Detect Trufflehog secret scanning activity with context-aware risk assessment\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: TRUFFLEHOG_ACTIVITY (global array)\n# Returns: Populates TRUFFLEHOG_ACTIVITY array with risk level (HIGH/MEDIUM/LOW) prefixes\ncheck_trufflehog_activity() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for Trufflehog activity and secret scanning...\"\n\n    # Look for trufflehog binary files (always HIGH RISK)\n    while IFS= read -r binary_file; do\n        if [[ -f \"$binary_file\" ]]; then\n            echo \"$binary_file:HIGH:Trufflehog binary found\" >> \"$TEMP_DIR/trufflehog_activity.txt\"\n        fi\n    done &#x3C; \"$TEMP_DIR/trufflehog_files.txt\"\n\n    # Combine script and code files for scanning\n    cat \"$TEMP_DIR/script_files.txt\" \"$TEMP_DIR/code_files.txt\" 2>/dev/null | sort -u > \"$TEMP_DIR/trufflehog_scan_files.txt\"\n\n    # HIGH PRIORITY: Dynamic TruffleHog download patterns (November 2025 attack)\n    { xargs grep -lE \"curl.*trufflehog|wget.*trufflehog|bunExecutable.*trufflehog|download.*trufflehog\" \\\n        &#x3C; \"$TEMP_DIR/trufflehog_scan_files.txt\" 2>/dev/null || true; } | while read -r file; do\n        [[ -n \"$file\" ]] &#x26;&#x26; echo \"$file:HIGH:November 2025 pattern - Dynamic TruffleHog download via curl/wget/Bun\" >> \"$TEMP_DIR/trufflehog_activity.txt\"\n    done\n\n    # HIGH PRIORITY: TruffleHog credential harvesting patterns\n    { xargs grep -lE \"TruffleHog.*scan.*credential|trufflehog.*env|trufflehog.*AWS|trufflehog.*NPM_TOKEN\" \\\n        &#x3C; \"$TEMP_DIR/trufflehog_scan_files.txt\" 2>/dev/null || true; } | while read -r file; do\n        [[ -n \"$file\" ]] &#x26;&#x26; echo \"$file:HIGH:TruffleHog credential scanning pattern detected\" >> \"$TEMP_DIR/trufflehog_activity.txt\"\n    done\n\n    # HIGH PRIORITY: Credential patterns with exfiltration indicators\n    { xargs grep -lE \"(AWS_ACCESS_KEY|GITHUB_TOKEN|NPM_TOKEN).*(webhook\\.site|curl|https\\.request)\" \\\n        &#x3C; \"$TEMP_DIR/trufflehog_scan_files.txt\" 2>/dev/null || true; } | \\\n        { grep -v \"/node_modules/\\|\\.d\\.ts$\" || true; } | while read -r file; do\n        [[ -n \"$file\" ]] &#x26;&#x26; echo \"$file:HIGH:Credential patterns with potential exfiltration\" >> \"$TEMP_DIR/trufflehog_activity.txt\"\n    done\n\n    # MEDIUM PRIORITY: Trufflehog references in source code (not node_modules/docs)\n    { xargs grep -l \"trufflehog\\|TruffleHog\" \\\n        &#x3C; \"$TEMP_DIR/trufflehog_scan_files.txt\" 2>/dev/null || true; } | \\\n        { grep -v \"/node_modules/\\|\\.md$\\|/docs/\\|\\.d\\.ts$\" || true; } | while read -r file; do\n        # Check if already flagged as HIGH\n        if [[ -n \"$file\" ]] &#x26;&#x26; ! grep -qF \"$file:\" \"$TEMP_DIR/trufflehog_activity.txt\" 2>/dev/null; then\n            echo \"$file:MEDIUM:Contains trufflehog references in source code\" >> \"$TEMP_DIR/trufflehog_activity.txt\"\n        fi\n    done\n\n    # MEDIUM PRIORITY: Credential scanning patterns (not in type definitions)\n    { xargs grep -lE \"AWS_ACCESS_KEY|GITHUB_TOKEN|NPM_TOKEN\" \\\n        &#x3C; \"$TEMP_DIR/trufflehog_scan_files.txt\" 2>/dev/null || true; } | \\\n        { grep -v \"/node_modules/\\|\\.d\\.ts$\\|/docs/\" || true; } | while read -r file; do\n        # Check if already flagged\n        if [[ -n \"$file\" ]] &#x26;&#x26; ! grep -qF \"$file:\" \"$TEMP_DIR/trufflehog_activity.txt\" 2>/dev/null; then\n            echo \"$file:MEDIUM:Contains credential scanning patterns\" >> \"$TEMP_DIR/trufflehog_activity.txt\"\n        fi\n    done\n\n    # LOW PRIORITY: Environment variable scanning with suspicious patterns\n    { xargs grep -lE \"(process\\.env|os\\.environ|getenv).*(scan|harvest|steal|exfiltrat)\" \\\n        &#x3C; \"$TEMP_DIR/trufflehog_scan_files.txt\" 2>/dev/null || true; } | \\\n        { grep -v \"/node_modules/\\|\\.d\\.ts$\" || true; } | while read -r file; do\n        if [[ -n \"$file\" ]] &#x26;&#x26; ! grep -qF \"$file:\" \"$TEMP_DIR/trufflehog_activity.txt\" 2>/dev/null; then\n            echo \"$file:LOW:Potentially suspicious environment variable access\" >> \"$TEMP_DIR/trufflehog_activity.txt\"\n        fi\n    done\n}\n\n# Function: check_shai_hulud_repos\n# Purpose: Detect Shai-Hulud worm repositories and malicious migration patterns\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: SHAI_HULUD_REPOS (global array)\n# Returns: Populates SHAI_HULUD_REPOS array with repository patterns and migration indicators\ncheck_shai_hulud_repos() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking for Shai-Hulud repositories and migration patterns...\"\n\n    # Performance Optimization: Use pre-collected git repositories\n    local git_repos_source\n    if [[ -f \"$TEMP_DIR/git_repos.txt\" ]]; then\n        git_repos_source=\"$TEMP_DIR/git_repos.txt\"\n    else\n        # Fallback with timeout protection\n        timeout 10 find \"$scan_dir\" -name \".git\" -type d 2>/dev/null | sed 's|/.git$||' > \"$TEMP_DIR/git_repos_fallback.txt\" || true\n        git_repos_source=\"$TEMP_DIR/git_repos_fallback.txt\"\n    fi\n\n    while IFS= read -r repo_dir; do\n        # Check if this is a repository named shai-hulud\n        local repo_name\n        repo_name=$(basename \"$repo_dir\")\n        if [[ \"$repo_name\" == *\"shai-hulud\"* ]] || [[ \"$repo_name\" == *\"Shai-Hulud\"* ]]; then\n            echo \"$repo_dir:Repository name contains 'Shai-Hulud'\" >> \"$TEMP_DIR/shai_hulud_repos.txt\"\n        fi\n\n        # Check for migration pattern repositories (new IoC)\n        if [[ \"$repo_name\" == *\"-migration\"* ]]; then\n            echo \"$repo_dir:Repository name contains migration pattern\" >> \"$TEMP_DIR/shai_hulud_repos.txt\"\n        fi\n\n        # Check for GitHub remote URLs containing shai-hulud\n        local git_config=\"$repo_dir/.git/config\"\n        if [[ -f \"$git_config\" ]]; then\n            if grep -q \"shai-hulud\\|Shai-Hulud\" \"$git_config\" 2>/dev/null; then\n                echo \"$repo_dir:Git remote contains 'Shai-Hulud'\" >> \"$TEMP_DIR/shai_hulud_repos.txt\"\n            fi\n        fi\n\n        # Check for double base64-encoded data.json (new IoC)\n        if [[ -f \"$repo_dir/data.json\" ]]; then\n            local content_sample\n            content_sample=$(head -5 \"$repo_dir/data.json\" 2>/dev/null || true)\n            if [[ \"$content_sample\" == *\"eyJ\"* ]] &#x26;&#x26; [[ \"$content_sample\" == *\"==\"* ]]; then\n                echo \"$repo_dir:Contains suspicious data.json (possible base64-encoded credentials)\" >> \"$TEMP_DIR/shai_hulud_repos.txt\"\n            fi\n        fi\n    done &#x3C; \"$git_repos_source\"\n}\n\n# Function: check_package_integrity\n# Purpose: Verify package lock files for compromised packages and version integrity\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: INTEGRITY_ISSUES (global array)\n# Returns: Populates INTEGRITY_ISSUES with compromised packages found in lockfiles\ncheck_package_integrity() {\n    local scan_dir=$1\n    print_status \"$BLUE\" \"   Checking package lock files for integrity issues...\"\n\n    # Check each lockfile\n    while IFS= read -r -d '' lockfile; do\n        if [[ -f \"$lockfile\" &#x26;&#x26; -r \"$lockfile\" ]]; then\n            org_file=\"$lockfile\"\n\n            # Transform pnpm-lock.yaml into pseudo-package-lock\n            if [[ \"$(basename \"$org_file\")\" == \"pnpm-lock.yaml\" ]]; then\n                lockfile=$(mktemp \"${TMPDIR:-/tmp}/lockfile.XXXXXXXX\")\n                transform_pnpm_yaml \"$org_file\" > \"$lockfile\"\n            fi\n\n            # Extract all package:version pairs from lockfile using AWK block parser\n            # This handles the JSON structure where name and version are on different lines\n            awk '\n                # Match \"node_modules/package-name\": { pattern\n                /^[[:space:]]*\"node_modules\\/[^\"]+\":/ {\n                    # Extract package name\n                    gsub(/.*\"node_modules\\//, \"\")\n                    gsub(/\".*/, \"\")\n                    current_pkg = $0\n                    in_block = 1\n                    next\n                }\n                # Match \"package-name\": { in packages section (older format)\n                /^[[:space:]]*\"[^\"\\/]+\":.*\\{/ &#x26;&#x26; !in_block {\n                    gsub(/^[[:space:]]*\"/, \"\")\n                    gsub(/\".*/, \"\")\n                    if ($0 !~ /^(name|version|resolved|integrity|dependencies|devDependencies|engines|funding|bin|peerDependencies)$/) {\n                        current_pkg = $0\n                        in_block = 1\n                    }\n                    next\n                }\n                # Extract version within block\n                in_block &#x26;&#x26; /\"version\":/ {\n                    gsub(/.*\"version\"[[:space:]]*:[[:space:]]*\"/, \"\")\n                    gsub(/\".*/, \"\")\n                    if (current_pkg != \"\" &#x26;&#x26; $0 ~ /^[0-9]/) {\n                        print current_pkg \":\" $0\n                    }\n                    in_block = 0\n                    current_pkg = \"\"\n                }\n                # End of block\n                in_block &#x26;&#x26; /^[[:space:]]*\\}/ {\n                    in_block = 0\n                    current_pkg = \"\"\n                }\n            ' \"$lockfile\" 2>/dev/null | while IFS=: read -r pkg_name pkg_version; do\n                # Check if this package:version is compromised using O(1) lookup\n                if [[ -v COMPROMISED_PACKAGES_MAP[\"$pkg_name:$pkg_version\"] ]]; then\n                    echo \"$org_file:Compromised package in lockfile: $pkg_name@$pkg_version\" >> \"$TEMP_DIR/integrity_issues.txt\"\n                fi\n            done\n\n            # Check for @ctrl packages (potential worm activity)\n            if grep -q \"@ctrl\" \"$lockfile\" 2>/dev/null; then\n                echo \"$org_file:Lockfile contains @ctrl packages (potential worm activity)\" >> \"$TEMP_DIR/integrity_issues.txt\"\n            fi\n\n            # Cleanup temp lockfile for pnpm\n            if [[ \"$(basename \"$org_file\")\" == \"pnpm-lock.yaml\" ]]; then\n                rm -f \"$lockfile\"\n            fi\n        fi\n    done &#x3C; &#x3C;(tr '\\n' '\\0' &#x3C; \"$TEMP_DIR/lockfiles.txt\")\n}\n\n# Function: check_typosquatting\n# Purpose: Detect typosquatting and homoglyph attacks in package dependencies\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: TYPOSQUATTING_WARNINGS (global array)\n# Returns: Populates TYPOSQUATTING_WARNINGS with Unicode chars, confusables, and similar names\ncheck_typosquatting() {\n    local scan_dir=$1\n\n    # Popular packages commonly targeted for typosquatting\n    local popular_packages=(\n        \"react\" \"vue\" \"angular\" \"express\" \"lodash\" \"axios\" \"typescript\"\n        \"webpack\" \"babel\" \"eslint\" \"jest\" \"mocha\" \"chalk\" \"debug\"\n        \"commander\" \"inquirer\" \"yargs\" \"request\" \"moment\" \"underscore\"\n        \"jquery\" \"bootstrap\" \"socket.io\" \"redis\" \"mongoose\" \"passport\"\n    )\n\n    # Track packages already warned about to prevent duplicates\n    local warned_packages=()\n\n    # Helper function to check if package already warned about\n    already_warned() {\n        local pkg=\"$1\"\n        local file=\"$2\"\n        local key=\"$file:$pkg\"\n        for warned in \"${warned_packages[@]}\"; do\n            [[ \"$warned\" == \"$key\" ]] &#x26;&#x26; return 0\n        done\n        return 1\n    }\n\n    # Cyrillic and Unicode lookalike characters for common ASCII characters\n    # Using od to detect non-ASCII characters in package names\n    while IFS= read -r -d '' package_file; do\n        if [[ -f \"$package_file\" &#x26;&#x26; -r \"$package_file\" ]]; then\n            # Extract package names from dependencies sections only\n            local package_names\n            package_names=$(awk '\n                /^[[:space:]]*\"dependencies\"[[:space:]]*:/ { in_deps=1; next }\n                /^[[:space:]]*\"devDependencies\"[[:space:]]*:/ { in_deps=1; next }\n                /^[[:space:]]*\"peerDependencies\"[[:space:]]*:/ { in_deps=1; next }\n                /^[[:space:]]*\"optionalDependencies\"[[:space:]]*:/ { in_deps=1; next }\n                /^[[:space:]]*}/ &#x26;&#x26; in_deps { in_deps=0; next }\n                in_deps &#x26;&#x26; /^[[:space:]]*\"[^\"]+\":/ {\n                    gsub(/^[[:space:]]*\"/, \"\", $0)\n                    gsub(/\".*$/, \"\", $0)\n                    if (length($0) > 1) print $0\n                }\n            ' \"$package_file\" | sort -u)\n\n            while IFS= read -r package_name; do\n                [[ -z \"$package_name\" ]] &#x26;&#x26; continue\n\n                # Skip if not a package name (too short, no alpha chars, etc)\n                [[ ${#package_name} -lt 2 ]] &#x26;&#x26; continue\n                echo \"$package_name\" | grep -q '[a-zA-Z]' || continue\n\n                # Check for non-ASCII characters using LC_ALL=C for compatibility\n                local has_unicode=0\n                if ! LC_ALL=C echo \"$package_name\" | grep -q '^[a-zA-Z0-9@/._-]*$'; then\n                    # Package name contains characters outside basic ASCII range\n                    has_unicode=1\n                fi\n\n                if [[ $has_unicode -eq 1 ]]; then\n                    # Simplified check - if it contains non-standard characters, flag it\n                    if ! already_warned \"$package_name\" \"$package_file\"; then\n                        echo \"$package_file:Potential Unicode/homoglyph characters in package: $package_name\" >> \"$TEMP_DIR/typosquatting_warnings.txt\"\n                        warned_packages+=(\"$package_file:$package_name\")\n                    fi\n                fi\n\n                # Check for confusable characters (common typosquatting patterns)\n                local confusables=(\n                    # Common character substitutions\n                    \"rn:m\" \"vv:w\" \"cl:d\" \"ii:i\" \"nn:n\" \"oo:o\"\n                )\n\n                for confusable in \"${confusables[@]}\"; do\n                    local pattern=\"${confusable%:*}\"\n                    local target=\"${confusable#*:}\"\n                    if echo \"$package_name\" | grep -q \"$pattern\"; then\n                        if ! already_warned \"$package_name\" \"$package_file\"; then\n                            echo \"$package_file:Potential typosquatting pattern '$pattern' in package: $package_name\" >> \"$TEMP_DIR/typosquatting_warnings.txt\"\n                            warned_packages+=(\"$package_file:$package_name\")\n                        fi\n                    fi\n                done\n\n                # Check similarity to popular packages using simple character distance\n                for popular in \"${popular_packages[@]}\"; do\n                    # Skip exact matches\n                    [[ \"$package_name\" == \"$popular\" ]] &#x26;&#x26; continue\n\n                    # Skip common legitimate variations\n                    case \"$package_name\" in\n                        \"test\"|\"tests\"|\"testing\") continue ;;  # Don't flag test packages\n                        \"types\"|\"util\"|\"utils\"|\"core\") continue ;;  # Common package names\n                        \"lib\"|\"libs\"|\"common\"|\"shared\") continue ;;\n                    esac\n\n                    # Check for single character differences (common typos) - but only for longer package names\n                    if [[ ${#package_name} -eq ${#popular} &#x26;&#x26; ${#package_name} -gt 4 ]]; then\n                        local diff_count=0\n                        for ((i=0; i&#x3C;${#package_name}; i++)); do\n                            if [[ \"${package_name:$i:1}\" != \"${popular:$i:1}\" ]]; then\n                                diff_count=$((diff_count+1))\n                            fi\n                        done\n\n                        if [[ $diff_count -eq 1 ]]; then\n                            # Additional check - avoid common legitimate variations\n                            if [[ \"$package_name\" != *\"-\"* &#x26;&#x26; \"$popular\" != *\"-\"* ]]; then\n                                if ! already_warned \"$package_name\" \"$package_file\"; then\n                                    echo \"$package_file:Potential typosquatting of '$popular': $package_name (1 character difference)\" >> \"$TEMP_DIR/typosquatting_warnings.txt\"\n                                    warned_packages+=(\"$package_file:$package_name\")\n                                fi\n                            fi\n                        fi\n                    fi\n\n                    # Check for common typosquatting patterns\n                    if [[ ${#package_name} -eq $((${#popular} - 1)) ]]; then\n                        # Missing character check\n                        for ((i=0; i&#x3C;=${#popular}; i++)); do\n                            local test_name=\"${popular:0:$i}${popular:$((i+1))}\"\n                            if [[ \"$package_name\" == \"$test_name\" ]]; then\n                                if ! already_warned \"$package_name\" \"$package_file\"; then\n                                    echo \"$package_file:Potential typosquatting of '$popular': $package_name (missing character)\" >> \"$TEMP_DIR/typosquatting_warnings.txt\"\n                                    warned_packages+=(\"$package_file:$package_name\")\n                                fi\n                                break\n                            fi\n                        done\n                    fi\n\n                    # Check for extra character\n                    if [[ ${#package_name} -eq $((${#popular} + 1)) ]]; then\n                        for ((i=0; i&#x3C;=${#package_name}; i++)); do\n                            local test_name=\"${package_name:0:$i}${package_name:$((i+1))}\"\n                            if [[ \"$test_name\" == \"$popular\" ]]; then\n                                if ! already_warned \"$package_name\" \"$package_file\"; then\n                                    echo \"$package_file:Potential typosquatting of '$popular': $package_name (extra character)\" >> \"$TEMP_DIR/typosquatting_warnings.txt\"\n                                    warned_packages+=(\"$package_file:$package_name\")\n                                fi\n                                break\n                            fi\n                        done\n                    fi\n                done\n\n                # Check for namespace confusion (e.g., @typescript_eslinter vs @typescript-eslint)\n                if [[ \"$package_name\" == @* ]]; then\n                    local namespace=\"${package_name%%/*}\"\n                    local package_part=\"${package_name#*/}\"\n\n                    # Common namespace typos\n                    local suspicious_namespaces=(\n                        \"@types\" \"@angular\" \"@typescript\" \"@react\" \"@vue\" \"@babel\"\n                    )\n\n                    for suspicious in \"${suspicious_namespaces[@]}\"; do\n                        if [[ \"$namespace\" != \"$suspicious\" ]] &#x26;&#x26; echo \"$namespace\" | grep -q \"${suspicious:1}\"; then\n                            # Check if it's a close match but not exact\n                            local ns_clean=\"${namespace:1}\"  # Remove @\n                            local sus_clean=\"${suspicious:1}\"  # Remove @\n\n                            if [[ ${#ns_clean} -eq ${#sus_clean} ]]; then\n                                local ns_diff=0\n                                for ((i=0; i&#x3C;${#ns_clean}; i++)); do\n                                    if [[ \"${ns_clean:$i:1}\" != \"${sus_clean:$i:1}\" ]]; then\n                                        ns_diff=$((ns_diff+1))\n                                    fi\n                                done\n\n                                if [[ $ns_diff -ge 1 &#x26;&#x26; $ns_diff -le 2 ]]; then\n                                    if ! already_warned \"$package_name\" \"$package_file\"; then\n                                        echo \"$package_file:Suspicious namespace variation: $namespace (similar to $suspicious)\" >> \"$TEMP_DIR/typosquatting_warnings.txt\"\n                                        warned_packages+=(\"$package_file:$package_name\")\n                                    fi\n                                fi\n                            fi\n                        fi\n                    done\n                fi\n\n            done &#x3C;&#x3C;&#x3C; \"$package_names\"\n        fi\n    # Use pre-categorized files from collect_all_files (performance optimization)\n    done &#x3C; &#x3C;(tr '\\n' '\\0' &#x3C; \"$TEMP_DIR/package_files.txt\")\n}\n\n# Function: check_network_exfiltration\n# Purpose: Detect network exfiltration patterns including suspicious domains and IPs\n# Args: $1 = scan_dir (directory to scan)\n# Modifies: $TEMP_DIR/network_exfiltration_warnings.txt (temp file)\n# Returns: Populates network_exfiltration_warnings.txt with hardcoded IPs and suspicious domains\ncheck_network_exfiltration() {\n    local scan_dir=$1\n\n    # Suspicious domains and patterns beyond webhook.site\n    local suspicious_domains=(\n        \"pastebin.com\" \"hastebin.com\" \"ix.io\" \"0x0.st\" \"transfer.sh\"\n        \"file.io\" \"anonfiles.com\" \"mega.nz\" \"dropbox.com/s/\"\n        \"discord.com/api/webhooks\" \"telegram.org\" \"t.me\"\n        \"ngrok.io\" \"localtunnel.me\" \"serveo.net\"\n        \"requestbin.com\" \"webhook.site\" \"beeceptor.com\"\n        \"pipedream.com\" \"zapier.com/hooks\"\n    )\n\n    # Suspicious IP patterns (private IPs used for exfiltration, common C2 patterns)\n    local suspicious_ip_patterns=(\n        \"10\\\\.0\\\\.\" \"192\\\\.168\\\\.\" \"172\\\\.(1[6-9]|2[0-9]|3[01])\\\\.\"  # Private IPs\n        \"[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}\\\\.[0-9]{1,3}:[0-9]{4,5}\"  # IP:Port\n    )\n\n    # Scan JavaScript, TypeScript, and JSON files for network patterns\n    while IFS= read -r -d '' file; do\n        if [[ -f \"$file\" &#x26;&#x26; -r \"$file\" ]]; then\n            # Check for hardcoded IP addresses (simplified)\n            # Skip vendor/library files to reduce false positives\n            if [[ \"$file\" != *\"/vendor/\"* &#x26;&#x26; \"$file\" != *\"/node_modules/\"* ]]; then\n                if grep -q '[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}' \"$file\" 2>/dev/null; then\n                    local ips_context\n                    ips_context=$(grep -o '[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}' \"$file\" 2>/dev/null | head -3 | tr '\\n' ' ')\n                    # Skip common safe IPs\n                    if [[ \"$ips_context\" != *\"127.0.0.1\"* &#x26;&#x26; \"$ips_context\" != *\"0.0.0.0\"* ]]; then\n                        # Check if it's a minified file to avoid showing file path details\n                        if [[ \"$file\" == *\".min.js\"* ]]; then\n                            echo \"$file:Hardcoded IP addresses found (minified file): $ips_context\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                        else\n                            echo \"$file:Hardcoded IP addresses found: $ips_context\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                        fi\n                    fi\n                fi\n            fi\n\n            # Check for suspicious domains (but avoid package-lock.json and vendor files to reduce noise)\n            if [[ \"$file\" != *\"package-lock.json\"* &#x26;&#x26; \"$file\" != *\"yarn.lock\"* &#x26;&#x26; \"$file\" != *\"/vendor/\"* &#x26;&#x26; \"$file\" != *\"/node_modules/\"* ]]; then\n                for domain in \"${suspicious_domains[@]}\"; do\n                    # Use word boundaries and URL patterns to avoid false positives like \"timeZone\" containing \"t.me\"\n                    # Updated pattern to catch property values like hostname: 'webhook.site'\n                    if grep -qE \"https?://[^[:space:]]*$domain|[[:space:]:,\\\"\\']$domain[[:space:]/\\\"\\',;]\" \"$file\" 2>/dev/null; then\n                        # Additional check - make sure it's not just a comment or documentation\n                        local suspicious_usage\n                        suspicious_usage=$(grep -E \"https?://[^[:space:]]*$domain|[[:space:]:,\\\"\\']$domain[[:space:]/\\\"\\',;]\" \"$file\" 2>/dev/null | grep -vE \"^[[:space:]]*#|^[[:space:]]*//\" 2>/dev/null | head -1 2>/dev/null || true) || true\n                        if [[ -n \"$suspicious_usage\" ]]; then\n                            # Get line number and context\n                            # FIX: grep -n prefixes lines with \"NNN:\" so we must account for that in comment filtering\n                            local line_info\n                            line_info=$(grep -nE \"https?://[^[:space:]]*$domain|[[:space:]:,\\\"\\']$domain[[:space:]/\\\"\\',;]\" \"$file\" 2>/dev/null | grep -vE \"^[0-9]+:[[:space:]]*#|^[0-9]+:[[:space:]]*//\" 2>/dev/null | head -1 2>/dev/null || true) || true\n                            local line_num\n                            line_num=$(echo \"$line_info\" | cut -d: -f1 2>/dev/null || true) || true\n\n                            # Check if it's a minified file or has very long lines\n                            if [[ \"$file\" == *\".min.js\"* ]] || [[ $(echo \"$suspicious_usage\" | wc -c 2>/dev/null || true) -gt 150 ]]; then\n                                # Extract just around the domain\n                                local snippet\n                                snippet=$(echo \"$suspicious_usage\" | grep -o \".\\{0,20\\}$domain.\\{0,20\\}\" 2>/dev/null | head -1 2>/dev/null || true) || true\n                                if [[ -n \"$line_num\" ]]; then\n                                    echo \"$file:Suspicious domain found: $domain at line $line_num: ...${snippet}...\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                                else\n                                    echo \"$file:Suspicious domain found: $domain: ...${snippet}...\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                                fi\n                            else\n                                local snippet\n                                snippet=$(echo \"$suspicious_usage\" | cut -c1-80 2>/dev/null || true) || true\n                                if [[ -n \"$line_num\" ]]; then\n                                    echo \"$file:Suspicious domain found: $domain at line $line_num: ${snippet}...\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                                else\n                                    echo \"$file:Suspicious domain found: $domain: ${snippet}...\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                                fi\n                            fi\n                        fi\n                    fi\n                done\n            fi\n\n            # Check for base64-encoded URLs (skip vendor files to reduce false positives)\n            if [[ \"$file\" != *\"/vendor/\"* &#x26;&#x26; \"$file\" != *\"/node_modules/\"* ]]; then\n                if grep -q 'atob(' \"$file\" 2>/dev/null || grep -q 'base64.*decode' \"$file\" 2>/dev/null; then\n                    # Get line number and a small snippet\n                    local line_num\n                    line_num=$(grep -n 'atob\\|base64.*decode' \"$file\" 2>/dev/null | head -1 2>/dev/null | cut -d: -f1 2>/dev/null || true) || true\n                    local snippet\n\n                    # For minified files, try to extract just the relevant part\n                    if [[ \"$file\" == *\".min.js\"* ]] || [[ $(head -1 \"$file\" 2>/dev/null | wc -c 2>/dev/null || true) -gt 500 ]]; then\n                        # Extract a small window around the atob call\n                        if [[ -n \"$line_num\" ]]; then\n                            snippet=$(sed -n \"${line_num}p\" \"$file\" 2>/dev/null | grep -o '.\\{0,30\\}atob.\\{0,30\\}' 2>/dev/null | head -1 2>/dev/null || true) || true\n                            if [[ -z \"$snippet\" ]]; then\n                                snippet=$(sed -n \"${line_num}p\" \"$file\" 2>/dev/null | grep -o '.\\{0,30\\}base64.*decode.\\{0,30\\}' 2>/dev/null | head -1 2>/dev/null || true) || true\n                            fi\n                            echo \"$file:Base64 decoding at line $line_num: ...${snippet}...\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                        else\n                            echo \"$file:Base64 decoding detected\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                        fi\n                    else\n                        snippet=$(sed -n \"${line_num}p\" \"$file\" | cut -c1-80)\n                        echo \"$file:Base64 decoding at line $line_num: ${snippet}...\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                    fi\n                fi\n            fi\n\n            # Check for DNS-over-HTTPS patterns\n            if grep -q \"dns-query\" \"$file\" 2>/dev/null || grep -q \"application/dns-message\" \"$file\" 2>/dev/null; then\n                echo \"$file:DNS-over-HTTPS pattern detected\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n            fi\n\n            # Check for WebSocket connections to unusual endpoints\n            if grep -q \"ws://\" \"$file\" 2>/dev/null || grep -q \"wss://\" \"$file\" 2>/dev/null; then\n                local ws_endpoints\n                ws_endpoints=$(grep -o 'wss\\?://[^\"'\\''[:space:]]*' \"$file\" 2>/dev/null || true)\n                while IFS= read -r endpoint; do\n                    [[ -z \"$endpoint\" ]] &#x26;&#x26; continue\n                    # Flag WebSocket connections that don't seem to be localhost or common development\n                    if [[ \"$endpoint\" != *\"localhost\"* &#x26;&#x26; \"$endpoint\" != *\"127.0.0.1\"* ]]; then\n                        echo \"$file:WebSocket connection to external endpoint: $endpoint\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                    fi\n                done &#x3C;&#x3C;&#x3C; \"$ws_endpoints\"\n            fi\n\n            # Check for suspicious HTTP headers\n            if grep -q \"X-Exfiltrate\\|X-Data-Export\\|X-Credential\" \"$file\" 2>/dev/null; then\n                echo \"$file:Suspicious HTTP headers detected\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n            fi\n\n            # Check for data encoding that might hide exfiltration (but be more selective)\n            if [[ \"$file\" != *\"/vendor/\"* &#x26;&#x26; \"$file\" != *\"/node_modules/\"* &#x26;&#x26; \"$file\" != *\".min.js\"* ]]; then\n                if grep -q \"btoa(\" \"$file\" 2>/dev/null; then\n                    # Check if it's near network operations (simplified to avoid hanging)\n                    if grep -C3 \"btoa(\" \"$file\" 2>/dev/null | grep -q \"\\(fetch\\|XMLHttpRequest\\|axios\\)\" 2>/dev/null; then\n                        # Additional check - make sure it's not just legitimate authentication\n                        if ! grep -C3 \"btoa(\" \"$file\" 2>/dev/null | grep -q \"Authorization:\\|Basic \\|Bearer \" 2>/dev/null; then\n                            # Get a small snippet around the btoa usage\n                            local line_num\n                            line_num=$(grep -n \"btoa(\" \"$file\" 2>/dev/null | head -1 2>/dev/null | cut -d: -f1 2>/dev/null || true) || true\n                            local snippet\n                            if [[ -n \"$line_num\" ]]; then\n                                snippet=$(sed -n \"${line_num}p\" \"$file\" 2>/dev/null | cut -c1-80 2>/dev/null || true) || true\n                                echo \"$file:Suspicious base64 encoding near network operation at line $line_num: ${snippet}...\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                            else\n                                echo \"$file:Suspicious base64 encoding near network operation\" >> \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n                            fi\n                        fi\n                    fi\n                fi\n            fi\n\n        fi\n    # Use pre-categorized files from collect_all_files (performance optimization)\n    done &#x3C; &#x3C;(tr '\\n' '\\0' &#x3C; \"$TEMP_DIR/code_files.txt\")\n}\n\n# Function: generate_report\n# Purpose: Generate comprehensive security report with risk stratification and findings\n# Args: $1 = paranoid_mode (\"true\" or \"false\" for extended checks)\n# Modifies: None (reads all global finding arrays)\n# Returns: Outputs formatted report to stdout with HIGH/MEDIUM/LOW risk sections\ngenerate_report() {\n    local paranoid_mode=\"$1\"\n    echo\n    print_status \"$BLUE\" \"==============================================\"\n    if [[ \"$paranoid_mode\" == \"true\" ]]; then\n        print_status \"$BLUE\" \"  SHAI-HULUD + PARANOID SECURITY REPORT\"\n    else\n        print_status \"$BLUE\" \"      SHAI-HULUD DETECTION REPORT\"\n    fi\n    print_status \"$BLUE\" \"==============================================\"\n    echo\n\n    local total_issues=0\n\n    # Reset global risk counters for this scan\n    high_risk=0\n    medium_risk=0\n\n    # Report malicious workflow files\n    if [[ -s \"$TEMP_DIR/workflow_files.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: Malicious workflow files detected:\"\n        while IFS= read -r file; do\n            echo \"   - $file\"\n            show_file_preview \"$file\" \"HIGH RISK: Known malicious workflow filename\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/workflow_files.txt\"\n    fi\n\n    # Report malicious file hashes\n    if [[ -s \"$TEMP_DIR/malicious_hashes.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: Files with known malicious hashes:\"\n        while IFS= read -r entry; do\n            local file_path=\"${entry%:*}\"\n            local hash=\"${entry#*:}\"\n            echo \"   - $file_path\"\n            echo \"     Hash: $hash\"\n            show_file_preview \"$file_path\" \"HIGH RISK: File matches known malicious SHA-256 hash\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/malicious_hashes.txt\"\n    fi\n\n    # Report November 2025 \"Shai-Hulud: The Second Coming\" attack files\n    if [[ -s \"$TEMP_DIR/bun_setup_files.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: November 2025 Bun attack setup files detected:\"\n        while IFS= read -r file; do\n            echo \"   - $file\"\n            show_file_preview \"$file\" \"HIGH RISK: setup_bun.js - Fake Bun runtime installation malware\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/bun_setup_files.txt\"\n    fi\n\n    if [[ -s \"$TEMP_DIR/bun_environment_files.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: November 2025 Bun environment payload detected:\"\n        while IFS= read -r file; do\n            echo \"   - $file\"\n            show_file_preview \"$file\" \"HIGH RISK: bun_environment.js - 10MB+ obfuscated credential harvesting payload\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/bun_environment_files.txt\"\n    fi\n\n    if [[ -s \"$TEMP_DIR/new_workflow_files.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: November 2025 malicious workflow files detected:\"\n        while IFS= read -r file; do\n            echo \"   - $file\"\n            show_file_preview \"$file\" \"HIGH RISK: formatter_*.yml - Malicious GitHub Actions workflow\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/new_workflow_files.txt\"\n    fi\n\n    if [[ -s \"$TEMP_DIR/actions_secrets_files.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: Actions secrets exfiltration files detected:\"\n        while IFS= read -r file; do\n            echo \"   - $file\"\n            show_file_preview \"$file\" \"HIGH RISK: actionsSecrets.json - Double Base64 encoded secrets exfiltration\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/actions_secrets_files.txt\"\n    fi\n\n    if [[ -s \"$TEMP_DIR/discussion_workflows.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: Malicious discussion-triggered workflows detected:\"\n        while IFS= read -r line; do\n            local file=\"${line%%:*}\"\n            local reason=\"${line#*:}\"\n            echo \"   - $file\"\n            echo \"     Reason: $reason\"\n            show_file_preview \"$file\" \"HIGH RISK: Discussion workflow - Enables arbitrary command execution via GitHub discussions\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/discussion_workflows.txt\"\n    fi\n\n    if [[ -s \"$TEMP_DIR/github_runners.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: Malicious GitHub Actions runners detected:\"\n        while IFS= read -r line; do\n            local dir=\"${line%%:*}\"\n            local reason=\"${line#*:}\"\n            echo \"   - $dir\"\n            echo \"     Reason: $reason\"\n            show_file_preview \"$dir\" \"HIGH RISK: GitHub Actions runner - Self-hosted backdoor for persistent access\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/github_runners.txt\"\n    fi\n\n    if [[ -s \"$TEMP_DIR/malicious_hashes.txt\" ]]; then\n        print_status \"$RED\" \"üö® CRITICAL: Hash-confirmed malicious files detected:\"\n        print_status \"$RED\" \"    These files match exact SHA256 hashes from security incident reports!\"\n        while IFS= read -r line; do\n            local file=\"${line%%:*}\"\n            local hash_info=\"${line#*:}\"\n            echo \"   - $file\"\n            echo \"     $hash_info\"\n            show_file_preview \"$file\" \"CRITICAL: Hash-confirmed malicious file - Exact match with known malware\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/malicious_hashes.txt\"\n    fi\n\n    if [[ -s \"$TEMP_DIR/destructive_patterns.txt\" ]]; then\n        print_status \"$RED\" \"üö® CRITICAL: Destructive payload patterns detected:\"\n        print_status \"$RED\" \"    ‚ö†Ô∏è  WARNING: These patterns can cause permanent data loss!\"\n        while IFS= read -r line; do\n            local file=\"${line%%:*}\"\n            local pattern_info=\"${line#*:}\"\n            echo \"   - $file\"\n            echo \"     Pattern: $pattern_info\"\n            show_file_preview \"$file\" \"CRITICAL: Destructive pattern - Can delete user files when credential theft fails\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/destructive_patterns.txt\"\n        print_status \"$RED\" \"    üìã IMMEDIATE ACTION REQUIRED: Quarantine these files and review for data destruction capabilities\"\n    fi\n\n    if [[ -s \"$TEMP_DIR/preinstall_bun_patterns.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: Fake Bun preinstall patterns detected:\"\n        while IFS= read -r file; do\n            echo \"   - $file\"\n            show_file_preview \"$file\" \"HIGH RISK: package.json contains malicious preinstall: node setup_bun.js\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/preinstall_bun_patterns.txt\"\n    fi\n\n    if [[ -s \"$TEMP_DIR/github_sha1hulud_runners.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: SHA1HULUD GitHub Actions runners detected:\"\n        while IFS= read -r file; do\n            echo \"   - $file\"\n            show_file_preview \"$file\" \"HIGH RISK: GitHub Actions workflow contains SHA1HULUD runner references\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/github_sha1hulud_runners.txt\"\n    fi\n\n    if [[ -s \"$TEMP_DIR/second_coming_repos.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: 'Shai-Hulud: The Second Coming' repositories detected:\"\n        while IFS= read -r repo_dir; do\n            echo \"   - $repo_dir\"\n            echo \"     Repository description: Sha1-Hulud: The Second Coming.\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/second_coming_repos.txt\"\n    fi\n\n    # Report compromised packages\n    if [[ -s \"$TEMP_DIR/compromised_found.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: Compromised package versions detected:\"\n        while IFS= read -r entry; do\n            local file_path=\"${entry%:*}\"\n            local package_info=\"${entry#*:}\"\n            echo \"   - Package: $package_info\"\n            echo \"     Found in: $file_path\"\n            show_file_preview \"$file_path\" \"HIGH RISK: Contains compromised package version: $package_info\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/compromised_found.txt\"\n        echo -e \"   ${YELLOW}NOTE: These specific package versions are known to be compromised.${NC}\"\n        echo -e \"   ${YELLOW}You should immediately update or remove these packages.${NC}\"\n        echo\n    fi\n\n    # Report suspicious packages\n    if [[ -s \"$TEMP_DIR/suspicious_found.txt\" ]]; then\n        print_status \"$YELLOW\" \"‚ö†Ô∏è  MEDIUM RISK: Suspicious package versions detected:\"\n        while IFS= read -r entry; do\n            local file_path=\"${entry%:*}\"\n            local package_info=\"${entry#*:}\"\n            echo \"   - Package: $package_info\"\n            echo \"     Found in: $file_path\"\n            show_file_preview \"$file_path\" \"MEDIUM RISK: Contains package version that could match compromised version: $package_info\"\n            medium_risk=$((medium_risk+1))\n        done &#x3C; \"$TEMP_DIR/suspicious_found.txt\"\n        echo -e \"   ${YELLOW}NOTE: Manual review required to determine if these are malicious.${NC}\"\n        echo\n    fi\n\n    # Report lockfile-safe packages\n    if [[ -s \"$TEMP_DIR/lockfile_safe_versions.txt\" ]]; then\n        print_status \"$BLUE\" \"‚ÑπÔ∏è  LOW RISK: Packages with safe lockfile versions:\"\n        while IFS= read -r entry; do\n            local file_path=\"${entry%:*}\"\n            local package_info=\"${entry#*:}\"\n            echo \"   - Package: $package_info\"\n            echo \"     Found in: $file_path\"\n        done &#x3C; \"$TEMP_DIR/lockfile_safe_versions.txt\"\n        echo -e \"   ${BLUE}NOTE: These package.json ranges could match compromised versions, but lockfiles pin to safe versions.${NC}\"\n        echo -e \"   ${BLUE}Your current installation is safe. Avoid running 'npm update' without reviewing changes.${NC}\"\n        echo\n    fi\n\n    # Report suspicious content\n    if [[ -s \"$TEMP_DIR/suspicious_content.txt\" ]]; then\n        print_status \"$YELLOW\" \"‚ö†Ô∏è  MEDIUM RISK: Suspicious content patterns:\"\n        while IFS= read -r entry; do\n            local file_path=\"${entry%:*}\"\n            local pattern=\"${entry#*:}\"\n            echo \"   - Pattern: $pattern\"\n            echo \"     Found in: $file_path\"\n            show_file_preview \"$file_path\" \"Contains suspicious pattern: $pattern\"\n            medium_risk=$((medium_risk+1))\n        done &#x3C; \"$TEMP_DIR/suspicious_content.txt\"\n        echo -e \"   ${YELLOW}NOTE: Manual review required to determine if these are malicious.${NC}\"\n        echo\n    fi\n\n    # Report cryptocurrency theft patterns\n    if [[ -s \"$TEMP_DIR/crypto_patterns.txt\" ]]; then\n        # Create temporary files for categorizing crypto patterns by risk level\n        local crypto_high_file=\"$TEMP_DIR/crypto_high_temp\"\n        local crypto_medium_file=\"$TEMP_DIR/crypto_medium_temp\"\n\n        while IFS= read -r entry; do\n            if [[ \"$entry\" == *\"HIGH RISK\"* ]] || [[ \"$entry\" == *\"Known attacker wallet\"* ]]; then\n                echo \"$entry\" >> \"$crypto_high_file\"\n            elif [[ \"$entry\" == *\"LOW RISK\"* ]]; then\n                echo \"Crypto pattern: $entry\" >> \"$TEMP_DIR/low_risk_findings.txt\"\n            else\n                echo \"$entry\" >> \"$crypto_medium_file\"\n            fi\n        done &#x3C; \"$TEMP_DIR/crypto_patterns.txt\"\n\n        # Report HIGH RISK crypto patterns\n        if [[ -s \"$crypto_high_file\" ]]; then\n            print_status \"$RED\" \"üö® HIGH RISK: Cryptocurrency theft patterns detected:\"\n            while IFS= read -r entry; do\n                echo \"   - ${entry}\"\n                high_risk=$((high_risk+1))\n            done &#x3C; \"$crypto_high_file\"\n            echo -e \"   ${RED}NOTE: These patterns strongly indicate crypto theft malware from the September 8 attack.${NC}\"\n            echo -e \"   ${RED}Immediate investigation and remediation required.${NC}\"\n            echo\n        fi\n\n        # Report MEDIUM RISK crypto patterns\n        if [[ -s \"$crypto_medium_file\" ]]; then\n            print_status \"$YELLOW\" \"‚ö†Ô∏è  MEDIUM RISK: Potential cryptocurrency manipulation patterns:\"\n            while IFS= read -r entry; do\n                echo \"   - ${entry}\"\n                medium_risk=$((medium_risk+1))\n            done &#x3C; \"$crypto_medium_file\"\n            echo -e \"   ${YELLOW}NOTE: These may be legitimate crypto tools or framework code.${NC}\"\n            echo -e \"   ${YELLOW}Manual review recommended to determine if they are malicious.${NC}\"\n            echo\n        fi\n\n        # Clean up temporary categorization files\n        [[ -f \"$crypto_high_file\" ]] &#x26;&#x26; rm -f \"$crypto_high_file\"\n        [[ -f \"$crypto_medium_file\" ]] &#x26;&#x26; rm -f \"$crypto_medium_file\"\n    fi\n\n    # Report git branches\n    if [[ -s \"$TEMP_DIR/git_branches.txt\" ]]; then\n        print_status \"$YELLOW\" \"‚ö†Ô∏è  MEDIUM RISK: Suspicious git branches:\"\n        while IFS= read -r entry; do\n            local repo_path=\"${entry%%:*}\"\n            local branch_info=\"${entry#*:}\"\n            echo \"   - Repository: $repo_path\"\n            echo \"     $branch_info\"\n            echo -e \"     ${BLUE}‚îå‚îÄ Git Investigation Commands:${NC}\"\n            echo -e \"     ${BLUE}‚îÇ${NC}  cd '$repo_path'\"\n            echo -e \"     ${BLUE}‚îÇ${NC}  git log --oneline -10 shai-hulud\"\n            echo -e \"     ${BLUE}‚îÇ${NC}  git show shai-hulud\"\n            echo -e \"     ${BLUE}‚îÇ${NC}  git diff main...shai-hulud\"\n            echo -e \"     ${BLUE}‚îî‚îÄ${NC}\"\n            echo\n            medium_risk=$((medium_risk+1))\n        done &#x3C; \"$TEMP_DIR/git_branches.txt\"\n        echo -e \"   ${YELLOW}NOTE: 'shai-hulud' branches may indicate compromise.${NC}\"\n        echo -e \"   ${YELLOW}Use the commands above to investigate each branch.${NC}\"\n        echo\n    fi\n\n    # Report suspicious postinstall hooks\n    if [[ -s \"$TEMP_DIR/postinstall_hooks.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: Suspicious postinstall hooks detected:\"\n        while IFS= read -r entry; do\n            local file_path=\"${entry%:*}\"\n            local hook_info=\"${entry#*:}\"\n            echo \"   - Hook: $hook_info\"\n            echo \"     Found in: $file_path\"\n            show_file_preview \"$file_path\" \"HIGH RISK: Contains suspicious postinstall hook: $hook_info\"\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/postinstall_hooks.txt\"\n        echo -e \"   ${YELLOW}NOTE: Postinstall hooks can execute arbitrary code during package installation.${NC}\"\n        echo -e \"   ${YELLOW}Review these hooks carefully for malicious behavior.${NC}\"\n        echo\n    fi\n\n    # Report Trufflehog activity by risk level\n    if [[ -s \"$TEMP_DIR/trufflehog_activity.txt\" ]]; then\n        # Create temporary files for categorizing trufflehog findings by risk level\n        local trufflehog_high_file=\"$TEMP_DIR/trufflehog_high_temp\"\n        local trufflehog_medium_file=\"$TEMP_DIR/trufflehog_medium_temp\"\n\n        # Categorize Trufflehog findings by risk level\n        while IFS= read -r entry; do\n            local file_path=\"${entry%%:*}\"\n            local risk_level=\"${entry#*:}\"\n            risk_level=\"${risk_level%%:*}\"\n            local activity_info=\"${entry#*:*:}\"\n\n            case \"$risk_level\" in\n                \"HIGH\")\n                    echo \"$file_path:$activity_info\" >> \"$trufflehog_high_file\"\n                    ;;\n                \"MEDIUM\")\n                    echo \"$file_path:$activity_info\" >> \"$trufflehog_medium_file\"\n                    ;;\n                \"LOW\")\n                    echo \"Trufflehog pattern: $file_path:$activity_info\" >> \"$TEMP_DIR/low_risk_findings.txt\"\n                    ;;\n            esac\n        done &#x3C; \"$TEMP_DIR/trufflehog_activity.txt\"\n\n        # Report HIGH RISK Trufflehog activity\n        if [[ -s \"$trufflehog_high_file\" ]]; then\n            print_status \"$RED\" \"üö® HIGH RISK: Trufflehog/secret scanning activity detected:\"\n            while IFS= read -r entry; do\n                local file_path=\"${entry%:*}\"\n                local activity_info=\"${entry#*:}\"\n                echo \"   - Activity: $activity_info\"\n                echo \"     Found in: $file_path\"\n                show_file_preview \"$file_path\" \"HIGH RISK: $activity_info\"\n                high_risk=$((high_risk+1))\n            done &#x3C; \"$trufflehog_high_file\"\n            echo -e \"   ${RED}NOTE: These patterns indicate likely malicious credential harvesting.${NC}\"\n            echo -e \"   ${RED}Immediate investigation and remediation required.${NC}\"\n            echo\n        fi\n\n        # Report MEDIUM RISK Trufflehog activity\n        if [[ -s \"$trufflehog_medium_file\" ]]; then\n            print_status \"$YELLOW\" \"‚ö†Ô∏è  MEDIUM RISK: Potentially suspicious secret scanning patterns:\"\n            while IFS= read -r entry; do\n                local file_path=\"${entry%:*}\"\n                local activity_info=\"${entry#*:}\"\n                echo \"   - Pattern: $activity_info\"\n                echo \"     Found in: $file_path\"\n                show_file_preview \"$file_path\" \"MEDIUM RISK: $activity_info\"\n                medium_risk=$((medium_risk+1))\n            done &#x3C; \"$trufflehog_medium_file\"\n            echo -e \"   ${YELLOW}NOTE: These may be legitimate security tools or framework code.${NC}\"\n            echo -e \"   ${YELLOW}Manual review recommended to determine if they are malicious.${NC}\"\n            echo\n        fi\n\n        # Clean up temporary categorization files\n        [[ -f \"$trufflehog_high_file\" ]] &#x26;&#x26; rm -f \"$trufflehog_high_file\"\n        [[ -f \"$trufflehog_medium_file\" ]] &#x26;&#x26; rm -f \"$trufflehog_medium_file\"\n    fi\n\n    # Report Shai-Hulud repositories\n    if [[ -s \"$TEMP_DIR/shai_hulud_repos.txt\" ]]; then\n        print_status \"$RED\" \"üö® HIGH RISK: Shai-Hulud repositories detected:\"\n        while IFS= read -r entry; do\n            local repo_path=\"${entry%:*}\"\n            local repo_info=\"${entry#*:}\"\n            echo \"   - Repository: $repo_path\"\n            echo \"     $repo_info\"\n            echo -e \"     ${BLUE}‚îå‚îÄ Repository Investigation Commands:${NC}\"\n            echo -e \"     ${BLUE}‚îÇ${NC}  cd '$repo_path'\"\n            echo -e \"     ${BLUE}‚îÇ${NC}  git log --oneline -10\"\n            echo -e \"     ${BLUE}‚îÇ${NC}  git remote -v\"\n            echo -e \"     ${BLUE}‚îÇ${NC}  ls -la\"\n            echo -e \"     ${BLUE}‚îî‚îÄ${NC}\"\n            echo\n            high_risk=$((high_risk+1))\n        done &#x3C; \"$TEMP_DIR/shai_hulud_repos.txt\"\n        echo -e \"   ${YELLOW}NOTE: 'Shai-Hulud' repositories are created by the malware for exfiltration.${NC}\"\n        echo -e \"   ${YELLOW}These should be deleted immediately after investigation.${NC}\"\n        echo\n    fi\n\n    # Store namespace warnings as LOW risk findings for later reporting\n    if [[ -s \"$TEMP_DIR/namespace_warnings.txt\" ]]; then\n        while IFS= read -r entry; do\n            local file_path=\"${entry%%:*}\"\n            local namespace_info=\"${entry#*:}\"\n            echo \"Namespace warning: $namespace_info (found in $(basename \"$file_path\"))\" >> \"$TEMP_DIR/low_risk_findings.txt\"\n        done &#x3C; \"$TEMP_DIR/namespace_warnings.txt\"\n    fi\n\n    # Report package integrity issues\n    if [[ -s \"$TEMP_DIR/integrity_issues.txt\" ]]; then\n        print_status \"$YELLOW\" \"‚ö†Ô∏è  MEDIUM RISK: Package integrity issues detected:\"\n        while IFS= read -r entry; do\n            local file_path=\"${entry%%:*}\"\n            local issue_info=\"${entry#*:}\"\n            echo \"   - Issue: $issue_info\"\n            echo \"     Found in: $file_path\"\n            show_file_preview \"$file_path\" \"Package integrity issue: $issue_info\"\n            medium_risk=$((medium_risk+1))\n        done &#x3C; \"$TEMP_DIR/integrity_issues.txt\"\n        echo -e \"   ${YELLOW}NOTE: These issues may indicate tampering with package dependencies.${NC}\"\n        echo -e \"   ${YELLOW}Verify package versions and regenerate lockfiles if necessary.${NC}\"\n        echo\n    fi\n\n    # Report typosquatting warnings (only in paranoid mode)\n    if [[ \"$paranoid_mode\" == \"true\" &#x26;&#x26; -s \"$TEMP_DIR/typosquatting_warnings.txt\" ]]; then\n        print_status \"$YELLOW\" \"‚ö†Ô∏è  MEDIUM RISK (PARANOID): Potential typosquatting/homoglyph attacks detected:\"\n        local typo_count=0\n        local total_typo_count\n        total_typo_count=$(wc -l &#x3C; \"$TEMP_DIR/typosquatting_warnings.txt\")\n\n        while IFS= read -r entry &#x26;&#x26; [[ $typo_count -lt 5 ]]; do\n            local file_path=\"${entry%%:*}\"\n            local warning_info=\"${entry#*:}\"\n            echo \"   - Warning: $warning_info\"\n            echo \"     Found in: $file_path\"\n            show_file_preview \"$file_path\" \"Potential typosquatting: $warning_info\"\n            medium_risk=$((medium_risk+1))\n            typo_count=$((typo_count+1))\n        done &#x3C; \"$TEMP_DIR/typosquatting_warnings.txt\"\n\n        if [[ $total_typo_count -gt 5 ]]; then\n            echo \"   - ... and $((total_typo_count - 5)) more typosquatting warnings (truncated for brevity)\"\n        fi\n        echo -e \"   ${YELLOW}NOTE: These packages may be impersonating legitimate packages.${NC}\"\n        echo -e \"   ${YELLOW}Verify package names carefully and check if they should be legitimate packages.${NC}\"\n        echo\n    fi\n\n    # Report network exfiltration warnings (only in paranoid mode)\n    if [[ \"$paranoid_mode\" == \"true\" &#x26;&#x26; -s \"$TEMP_DIR/network_exfiltration_warnings.txt\" ]]; then\n        print_status \"$YELLOW\" \"‚ö†Ô∏è  MEDIUM RISK (PARANOID): Network exfiltration patterns detected:\"\n        local net_count=0\n        local total_net_count\n        total_net_count=$(wc -l &#x3C; \"$TEMP_DIR/network_exfiltration_warnings.txt\")\n\n        while IFS= read -r entry &#x26;&#x26; [[ $net_count -lt 5 ]]; do\n            local file_path=\"${entry%%:*}\"\n            local warning_info=\"${entry#*:}\"\n            echo \"   - Warning: $warning_info\"\n            echo \"     Found in: $file_path\"\n            show_file_preview \"$file_path\" \"Network exfiltration pattern: $warning_info\"\n            medium_risk=$((medium_risk+1))\n            net_count=$((net_count+1))\n        done &#x3C; \"$TEMP_DIR/network_exfiltration_warnings.txt\"\n\n        if [[ $total_net_count -gt 5 ]]; then\n            echo \"   - ... and $((total_net_count - 5)) more network warnings (truncated for brevity)\"\n        fi\n        echo -e \"   ${YELLOW}NOTE: These patterns may indicate data exfiltration or communication with C2 servers.${NC}\"\n        echo -e \"   ${YELLOW}Review network connections and data flows carefully.${NC}\"\n        echo\n    fi\n\n    total_issues=$((high_risk + medium_risk))\n    local low_risk_count=0\n    if [[ -s \"$TEMP_DIR/low_risk_findings.txt\" ]]; then\n        low_risk_count=$(wc -l &#x3C; \"$TEMP_DIR/low_risk_findings.txt\" 2>/dev/null || echo \"0\")\n    fi\n\n    # Summary\n    print_status \"$BLUE\" \"==============================================\"\n    if [[ $total_issues -eq 0 ]]; then\n        print_status \"$GREEN\" \"‚úÖ No indicators of Shai-Hulud compromise detected.\"\n        print_status \"$GREEN\" \"Your system appears clean from this specific attack.\"\n\n        # Show low risk findings if any (informational only)\n        if [[ $low_risk_count -gt 0 ]]; then\n            echo\n            print_status \"$BLUE\" \"‚ÑπÔ∏è  LOW RISK FINDINGS (informational only):\"\n            while IFS= read -r finding; do\n                echo \"   - $finding\"\n            done &#x3C; \"$TEMP_DIR/low_risk_findings.txt\"\n            echo -e \"   ${BLUE}NOTE: These are likely legitimate framework code or dependencies.${NC}\"\n        fi\n    else\n        print_status \"$RED\" \"   SUMMARY:\"\n        print_status \"$RED\" \"   High Risk Issues: $high_risk\"\n        print_status \"$YELLOW\" \"   Medium Risk Issues: $medium_risk\"\n        if [[ $low_risk_count -gt 0 ]]; then\n            print_status \"$BLUE\" \"   Low Risk (informational): $low_risk_count\"\n        fi\n        print_status \"$BLUE\" \"   Total Critical Issues: $total_issues\"\n        echo\n        print_status \"$YELLOW\" \"‚ö†Ô∏è  IMPORTANT:\"\n        print_status \"$YELLOW\" \"   - High risk issues likely indicate actual compromise\"\n        print_status \"$YELLOW\" \"   - Medium risk issues require manual investigation\"\n        print_status \"$YELLOW\" \"   - Low risk issues are likely false positives from legitimate code\"\n        if [[ \"$paranoid_mode\" == \"true\" ]]; then\n            print_status \"$YELLOW\" \"   - Issues marked (PARANOID) are general security checks, not Shai-Hulud specific\"\n        fi\n        print_status \"$YELLOW\" \"   - Consider running additional security scans\"\n        print_status \"$YELLOW\" \"   - Review your npm audit logs and package history\"\n\n        if [[ $low_risk_count -gt 0 ]] &#x26;&#x26; [[ $total_issues -lt 5 ]]; then\n            echo\n            print_status \"$BLUE\" \"‚ÑπÔ∏è  LOW RISK FINDINGS (likely false positives):\"\n            while IFS= read -r finding; do\n                echo \"   - $finding\"\n            done &#x3C; \"$TEMP_DIR/low_risk_findings.txt\"\n            echo -e \"   ${BLUE}NOTE: These are typically legitimate framework patterns.${NC}\"\n        fi\n    fi\n    print_status \"$BLUE\" \"==============================================\"\n}\n\n# Function: main\n# Purpose: Main entry point - parse arguments, load data, run all checks, generate report\n# Args: Command line arguments (--paranoid, --help, --parallelism N, directory_path)\n# Modifies: All global arrays via detection functions\n# Returns: Exit code 0 for clean, 1 for high-risk findings, 2 for medium-risk findings\nmain() {\n    local paranoid_mode=false\n    local scan_dir=\"\"\n\n    # Load compromised packages from external file\n    load_compromised_packages\n\n    # Create temporary directory for file-based findings storage\n    create_temp_dir\n\n    # Set up signal handling for clean termination of background processes\n    trap 'cleanup_and_exit' INT TERM\n\n    # Parse arguments\n    while [[ $# -gt 0 ]]; do\n        case $1 in\n            --paranoid)\n                paranoid_mode=true\n                ;;\n            --help|-h)\n                usage\n                ;;\n            --parallelism)\n                re='^[0-9]+$'\n                if ! [[ $2 =~ $re ]] ; then\n                    echo \"${RED}error: Not a number${NC}\" >&#x26;2;\n                    usage\n                fi\n                PARALLELISM=$2\n                shift\n                ;;\n            -*)\n                echo \"Unknown option: $1\"\n                usage\n                ;;\n            *)\n                if [[ -z \"$scan_dir\" ]]; then\n                    scan_dir=\"$1\"\n                else\n                    echo \"Too many arguments\"\n                    usage\n                fi\n                ;;\n        esac\n        shift\n    done\n\n    if [[ -z \"$scan_dir\" ]]; then\n        usage\n    fi\n\n    if [[ ! -d \"$scan_dir\" ]]; then\n        print_status \"$RED\" \"Error: Directory '$scan_dir' does not exist.\"\n        exit 1\n    fi\n\n    # Convert to absolute path\n    if ! scan_dir=$(cd \"$scan_dir\" &#x26;&#x26; pwd); then\n        print_status \"$RED\" \"Error: Unable to access directory '$scan_dir' or convert to absolute path.\"\n        exit 1\n    fi\n\n    # Initialize timing\n    SCAN_START_TIME=$(date +%s%N 2>/dev/null || echo \"$(date +%s)000000000\")\n\n    print_status \"$GREEN\" \"Starting Shai-Hulud detection scan...\"\n    if [[ \"$paranoid_mode\" == \"true\" ]]; then\n        print_status \"$BLUE\" \"Scanning directory: $scan_dir (with paranoid mode enabled)\"\n    else\n        print_status \"$BLUE\" \"Scanning directory: $scan_dir\"\n    fi\n    echo\n\n    # Collect all files in a single pass for performance optimization\n    print_status \"$ORANGE\" \"[Stage 1/6] Collecting file inventory for analysis\"\n    collect_all_files \"$scan_dir\"\n\n    # Show summary of collected files\n    local total_files=$(wc -l &#x3C; \"$TEMP_DIR/all_files_raw.txt\" 2>/dev/null || echo \"0\")\n    print_stage_complete \"File collection ($total_files files)\"\n\n    # Run core Shai-Hulud detection checks (sequential for reliability)\n    print_status \"$ORANGE\" \"[Stage 2/6] Core detection (workflows, hashes, packages, hooks)\"\n    check_workflow_files \"$scan_dir\"\n    check_file_hashes \"$scan_dir\"\n    check_packages \"$scan_dir\"\n    check_postinstall_hooks \"$scan_dir\"\n    print_stage_complete \"Core detection\"\n\n    # Content analysis\n    print_status \"$ORANGE\" \"[Stage 3/6] Content analysis (patterns, crypto, trufflehog, git)\"\n    check_content \"$scan_dir\"\n    check_crypto_theft_patterns \"$scan_dir\"\n    check_trufflehog_activity \"$scan_dir\"\n    check_git_branches \"$scan_dir\"\n    print_stage_complete \"Content analysis\"\n\n    # Repository analysis\n    print_status \"$ORANGE\" \"[Stage 4/6] Repository analysis (repos, integrity, bun, workflows)\"\n    check_shai_hulud_repos \"$scan_dir\"\n    check_package_integrity \"$scan_dir\"\n    check_bun_attack_files \"$scan_dir\"\n    check_new_workflow_patterns \"$scan_dir\"\n    print_stage_complete \"Repository analysis\"\n\n    # Advanced pattern detection\n    print_status \"$ORANGE\" \"[Stage 5/6] Advanced detection (discussions, runners, destructive)\"\n    check_discussion_workflows \"$scan_dir\"\n    check_github_runners \"$scan_dir\"\n    check_destructive_patterns \"$scan_dir\"\n    check_preinstall_bun_patterns \"$scan_dir\"\n    print_stage_complete \"Advanced detection\"\n\n    # Final checks\n    print_status \"$ORANGE\" \"[Stage 6/6] Final checks (actions runner, second coming repos)\"\n    check_github_actions_runner \"$scan_dir\"\n    check_second_coming_repos \"$scan_dir\"\n    print_stage_complete \"Final checks\"\n\n    # Run additional security checks only in paranoid mode\n    if [[ \"$paranoid_mode\" == \"true\" ]]; then\n        print_status \"$BLUE\" \"[Paranoid] Running extra security checks...\"\n        check_typosquatting \"$scan_dir\"\n        check_network_exfiltration \"$scan_dir\"\n        print_stage_complete \"Paranoid mode checks\"\n    fi\n\n    # Generate report\n    print_status \"$BLUE\" \"Generating report...\"\n    generate_report \"$paranoid_mode\"\n    print_stage_complete \"Total scan time\"\n\n    # Return appropriate exit code based on findings\n    if [[ $high_risk -gt 0 ]]; then\n        exit 1  # High risk findings detected\n    elif [[ $medium_risk -gt 0 ]]; then\n        exit 2  # Medium risk findings detected\n    else\n        exit 0  # Clean - no significant findings\n    fi\n}\n\n# Run main function with all arguments\nmain \"$@\"\n</code></pre>\n</details>\n<p><strong>To run this script:</strong></p>\n<ol>\n<li>Create a new file named <code>shai-hulud-detector.sh</code> and paste the code from above into it.</li>\n<li>Run the following commands:</li>\n</ol>\n<pre><code class=\"language-shell\"># Make the script executable\nchmod +x shai-hulud-detector.sh\n\n# Scan your project for Shai-Hulud indicators\n./shai-hulud-detector.sh /path/to/your/project\n\n# For comprehensive security scanning\n./shai-hulud-detector.sh --paranoid /path/to/your/project\n</code></pre>\n<ul>\n<li><strong>Why:</strong> You must cut the root of the infection to prevent immediate re-compromise.</li>\n</ul>\n<h2 id=\"3-triage-decode-every-leaked-secret-and-list-exposed-services\"><a href=\"#3-triage-decode-every-leaked-secret-and-list-exposed-services\" aria-hidden=\"true\" tabindex=\"-1\">3. Triage: Decode Every Leaked Secret and List Exposed Services</a></h2>\n<ul>\n<li><strong>Action:</strong> Using the downloaded <code>.json</code> files from the GitHub repository created by the malware and decode their contents using the supplied script. Every file - <code>actionsSecrets.json, contents.json</code>, <code>cloud.json</code>, <code>environment.json</code>, etc. - must be decoded.</li>\n</ul>\n<pre><code class=\"language-shell\">#!/bin/bash\n\n# Execute this from inside the directory containing the stolen .json files.\necho \"--- Starting Shai-Hulud Double-Base64 Decoding ---\"\n\n# Loop through all files matching the .json extension\nfor encoded_file in *.json; do\n    \n    # Check if the file actually exists (prevents running if no files match)\n    if [ -f \"$encoded_file\" ]; then\n        decoded_output=\"${encoded_file}.decoded\"\n        \n        echo \"Processing: $encoded_file -> Saving to: $decoded_output\"\n        \n        # Double-decode the content and redirect output to the new file\n        # The syntax for the double-decode: cat | base64 -d | base64 -d > output\n        cat \"$encoded_file\" | base64 -d | base64 -d > \"$decoded_output\"\n        \n        # Check if the decode was successful (i.e., the output file is not empty)\n        if [ -s \"$decoded_output\" ]; then\n            echo \"   ‚úÖ Successfully decoded.\"\n        else\n            echo \"   ‚ùå Decoding failed or resulted in an empty file.\"\n        fi\n    fi\ndone\n\necho \"--- Decoding Complete. Review *.json.decoded files for leaked secrets. ---\"\n</code></pre>\n<p>Script to decode the JSON files created by Sha1-hulud</p>\n<pre><code class=\"language-shell\">chmod +x decode.sh # containing the code above, and being in the folder containing the jsons.\n\n./decode.sh \n</code></pre>\n<p><img src=\"/img/RealTimePostImage/post/shai-hulud-remediation/decode-result.png\">\n<strong>Result after decoding</strong></p>\n<p><strong>Each .decoded file contains a JSON with all the leaked secrets.</strong></p>\n<ul>\n<li><strong>Why</strong>: This step yields the definitive, un-obfuscated list of compromised secrets and the specific services they grant access to. This list is the foundation for your rotation plan.</li>\n</ul>\n<h2 id=\"4-remediation-rotate-the-leaked-credentials\"><a href=\"#4-remediation-rotate-the-leaked-credentials\" aria-hidden=\"true\" tabindex=\"-1\">4. Remediation: Rotate the leaked credentials</a></h2>\n<ul>\n<li><strong>Action:</strong> Rotate every credential identified in the decoded JSON files. Assume every secret listed is compromised and immediately usable by the attacker. This includes all GitHub PATs, npm tokens, all cloud service keys (AWS, Azure, GCP), all tokens gathered by TruffleHog and all credentials stolen from the Github Action execution. In short, all credentials present in the files.</li>\n<li><strong>Why:</strong> Rotation renders the attacker's stolen goods worthless, eliminating their ability to move laterally or maintain access.</li>\n</ul>\n<h2 id=\"5-post-incident-audit-logs-for-persistence-and-untrusted-connections\"><a href=\"#5-post-incident-audit-logs-for-persistence-and-untrusted-connections\" aria-hidden=\"true\" tabindex=\"-1\">5. Post-Incident: Audit Logs for Persistence and Untrusted Connections</a></h2>\n<ul>\n<li>\n<p><strong>Action:</strong> Examine the Leaked Service account‚Äôs Security Log (or Activity Log) for activity spanning the time <em>after</em> the Github repository was created. Look specifically for:</p>\n<ul>\n<li><strong>Untrusted Connections</strong>: The authorization of any unrecognized third-party OAuth applications, SSH keys, or webhooks.</li>\n<li><strong>Unusual Activity</strong>: Look for the creation of new tokens or unexpected login attempts.</li>\n<li>If an untrusted service is found, immediately block it and do not re-enable it until a thorough forensic investigation confirms no further malicious payloads or backdoors were installed via that connection.</li>\n</ul>\n</li>\n<li><strong>Why</strong>: The Shai-Hulud worm is aggressive; its primary goal is exfiltration, but its secondary goal may be persistence. Identifying and blocking any unauthorized service or token is critical to preventing re-entry and ensuring a complete eviction.</li>\n</ul>\n<h2 id=\"6-prevent-future-infection-use-curationimmaturity-policy\"><a href=\"#6-prevent-future-infection-use-curationimmaturity-policy\" aria-hidden=\"true\" tabindex=\"-1\">6. Prevent future infection: use Curation/Immaturity Policy</a></h2>\n<p>The long-term solution is to prevent malicious packages from ever reaching developers or runners.</p>\n<ul>\n<li>\n<p><strong>Action:</strong> Implement <strong>Curation/Immaturity Policies</strong> within your artifact repository (e.g., JFrog Artifactory).</p>\n<ul>\n<li><strong>Quarantine Unknown Packages:</strong> Configure the repository to automatically block or quarantine any package (including new versions of existing packages) that has not been explicitly approved and scanned by your security team, <a href=\"https://jfrog.com/help/r/jfrog-security-user-guide/products/curation/configure-curation/create-policies/list-of-available-conditions\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">for example by using JFrog Curation</a>.</li>\n<li><strong>Require Security Scanning:</strong> Enforce a policy that scans all new dependencies for known vulnerabilities and malicious code signatures <strong>before</strong> they are proxied from the public registry (npm, PyPI) to your internal, trusted repository.</li>\n</ul>\n</li>\n<li><strong>Why:</strong> This creates a mandatory security gate, ensuring that the next supply chain attack, like Shai-Hulud, is quarantined at the repository level, isolating your developers from the threat.</li>\n</ul>\n<p><video src=\"/img/RealTimePostImage/post/shai-hulud-remediation/immature-policy.mp4\" controls></video></p>\n<p><strong>JFrog <a href=\"https://jfrog.com/xray/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Xray</a> and <a href=\"https://jfrog.com/curation/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Curation</a> customers are fully protected from this attack vector, as all of the campaign's packages are already marked as malicious.</strong></p>\n<p>In addition, for JFrog Curation customers - </p>\n<ol>\n<li>Consider enabling <a href=\"https://jfrog.com/help/r/jfrog-security-user-guide/products/curation/configure-curation/fallback-behavior-for-blocked-packages\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Compliant Version Selection</a> in order to keep developers safe without hurting their workflow. With CVS - the latest, non-malicious version of each package will be transparently served by Curation.</li>\n<li>Consider enabling the <a href=\"https://jfrog.com/help/r/jfrog-security-user-guide/products/curation/configure-curation/create-policies/list-of-available-conditions\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Package version is immature</a> policy as show in the above video, in order to reject package versions which are too new. This will allow you to constantly stay immune to similar dependency hijack attacks.</li>\n<li>Curation customers can utilize Catalog's new JFrog label, \"Shai Hulud - The second coming\", which enumerates all the compromised packages.\n<img src=\"/img/RealTimePostImage/post/shai-hulud-v2-jfrog-catalog.png\"></li>\n</ol>\n","excerpt":"Shai-Hulud remediation guide","minutes":"5","schema":"{\n \"@context\": \"https://schema.org\",\n \"@type\": \"TechArticle\",\n \"mainEntityOfPage\": {\n   \"@type\": \"WebPage\",\n   \"@id\": \"https://research.jfrog.com/post/shai-hulud-the-second-coming-remediation-guidance/\"\n },\n \"headline\": \"Shai-Hulud Protection Guide: Detect, Remove, Prevent\",\n   \"description\": \"Complete guide to protecting against Shai-Hulud npm supply chain attacks. Includes detection scripts, credential rotation steps, and prevention strategies.\",\n \"author\": {\n   \"@type\": \"Person\",\n   \"name\": \"David Cohen\"\n },\n  \"publisher\": {\n   \"@type\": \"Organization\",\n   \"@id\":\"https://jfrog.com/#organization\",\n   \"name\": \"JFrog \",\n   \"logo\": {\n     \"@type\": \"ImageObject\",\n     \"url\": \"https://research.jfrog.com/assets/static/jfrog-logo-svg.5788598.74a3bea875bf053c65a0663c9ec9a0fd.svg\"\n   }\n },\n \"datePublished\": \"2025-11-26\",\n \"dateModified\": \"2025-11-26\"}\n","canonical":""}},"context":{}}