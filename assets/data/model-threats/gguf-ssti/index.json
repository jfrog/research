{"hash":"6a92b1a88c6f97ed1198b513f9e51d14f98b7849","data":{"modelThreatsPost":{"title":"GGUF-SSTI","path":"/model-threats/gguf-ssti/","content":"<h2 id=\"overview\"><a href=\"#overview\" aria-hidden=\"true\" tabindex=\"-1\">Overview</a></h2>\n<p>A GGUF model may contain a <a href=\"https://palletsprojects.com/projects/jinja/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Jinja2</a> template which may cause server-side template injection (<a href=\"https://portswigger.net/web-security/server-side-template-injection\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">SSTI</a>) that leads to <strong>execution of malicious Python code</strong> when the model is loaded.</p>\n<p><u>Important Note</u> - The only publicly known case where loading a GGUF model leads to dangerous server-side template injection is related to the <a href=\"https://github.com/abetlen/llama-cpp-python/security/advisories/GHSA-56xg-wfcc-g829\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">CVE-2024-34359</a> (\"Llama Drama\") vulnerability. This vulnerability is only exploitable when loading a GGUF model using a vulnerable version of the <a href=\"https://pypi.org/project/llama-cpp-python/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">llama-cpp-python</a> library (<code>llama-cpp-python</code> &#x3C; 0.2.72). This means that arbitrary code execution <u>will not occur</u> when loading a malicious GGUF model into <code>llama-cpp-python</code> >= 0.2.72 or into other GGUF-compatible libraries, such as <a href=\"https://ollama.com/download\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ollama</a> .</p>\n<p>The GGUF model format is a binary format optimized for quickly loading and storing models. One of the features of the GGUF model format, is the ability to store a <strong>chat template</strong> in the Model's metadata (<code>tokenizer.chat_template</code>).</p>\n<p><img src=\"/img/chat_template.png\"></p>\n<p>A chat template simply defines how a chat (prompt) interaction with the model will look like. The chat template in a GGUF model is written using the Jinja2 template language. Since the Jinja2 template language supports execution of arbitrary Python code, loading arbitrary Jinja2 templates from a GGUF model into an <strong>unsandboxed</strong> Jinja2 engine leads to arbitrary code execution.</p>\n<p>For example - the following Jinja2 template, which can be inserted into a GGUF model's <code>chat_template</code> metadata parameter, will run the shell command <code>touch /tmp/retr0reg</code> if the GGUF model is loaded in an unsandboxed environment -</p>\n<pre><code>{% for x in ().__class__.__base__.__subclasses__() %}{% if \"warning\" in x.__name__ %}{{x()._module.__builtins__['__import__']('os').popen(\"touch /tmp/retr0reg\")}}{%endif%}{% endfor %}\n</code></pre>\n<h2 id=\"time-of-infection\"><a href=\"#time-of-infection\" aria-hidden=\"true\" tabindex=\"-1\">Time of Infection</a></h2>\n<p><strong>[v] Model Load</strong></p>\n<p>[] Model Query</p>\n<p>[] Other</p>\n<h2 id=\"evidence-extraction-and-false-positive-elimination\"><a href=\"#evidence-extraction-and-false-positive-elimination\" aria-hidden=\"true\" tabindex=\"-1\">Evidence Extraction and False Positive Elimination</a></h2>\n<p>To safely determine if the suspected GGUF model contains a malicious Jinja2 template -</p>\n<ol>\n<li>Parse the GGUF model's metadata parameters and extract the <code>tokenizer.chat_template</code> string</li>\n<li>Inspect the chat template data for suspicious strings such as <code>__class__</code>, <code>os</code>, <code>subprocess</code>, <code>eval</code> and <code>exec</code></li>\n</ol>\n<p>JFrog conducts metadata extraction and detailed analysis on each GGUF model in order to determine whether any malicious code is present.</p>\n<h2 id=\"additional-information\"><a href=\"#additional-information\" aria-hidden=\"true\" tabindex=\"-1\">Additional Information</a></h2>\n<ul>\n<li><a href=\"https://github.com/abetlen/llama-cpp-python/security/advisories/GHSA-56xg-wfcc-g829\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/abetlen/llama-cpp-python/security/advisories/GHSA-56xg-wfcc-g829</a></li>\n<li><a href=\"https://github.com/huggingface/smol-course/blob/main/1_instruction_tuning/chat_templates.md\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/huggingface/smol-course/blob/main/1_instruction_tuning/chat_templates.md</a></li>\n<li><a href=\"https://techtonics.medium.com/secure-templating-with-jinja2-understanding-ssti-and-jinja2-sandbox-environment-b956edd60456\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://techtonics.medium.com/secure-templating-with-jinja2-understanding-ssti-and-jinja2-sandbox-environment-b956edd60456</a></li>\n</ul>\n","description":"GGUF model attempting template injection for arbitrary code execution"}},"context":{}}