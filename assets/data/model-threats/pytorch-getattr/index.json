{"hash":"16a3b2aae6d851038dc28f60b7b780cc42312696","data":{"modelThreatsPost":{"title":"PYTORCH-GETATTR","path":"/model-threats/pytorch-getattr/","content":"<h2 id=\"overview\"><a href=\"#overview\" aria-hidden=\"true\" tabindex=\"-1\">Overview</a></h2>\n<p>A PyTorch model may contain serialized Pickle data which will cause execution of potentially malicious Python code when the model is loaded. Specifically - the potentially malicious Python code may contain a reference to the getattr() function.</p>\n<p>While <code>getattr()</code> is a basic method used in many legitimate codebases, it can be dangerous when misused.</p>\n<h2 id=\"potential-malicious-use-of-getattr\"><a href=\"#potential-malicious-use-of-getattr\" aria-hidden=\"true\" tabindex=\"-1\">Potential Malicious Use of getattr</a></h2>\n<p>Consider this malicious example:</p>\n<pre><code class=\"language-python\">class Exploit:\n    def __init__(self):\n        self.malicious_method = lambda: __import__('os').system('rm -rf /')\n\ndef dangerous_getattr(obj, method_name):\n    # An attacker could potentially execute arbitrary system commands\n    return getattr(obj, method_name)()\n\nexploit = Exploit()\n# This could potentially execute a destructive system command\ndangerous_getattr(exploit, 'malicious_method')\n</code></pre>\n<p>In this example, <code>getattr()</code> allows dynamically calling a method that:</p>\n<ul>\n<li>Imports the <code>os</code> module</li>\n<li>Executes a destructive system command</li>\n<li>Could potentially delete critical system files</li>\n<li>Demonstrates how runtime attribute lookup can be exploited for unauthorized actions</li>\n</ul>\n<h2 id=\"evidence-extraction-and-false-positive-elimination\"><a href=\"#evidence-extraction-and-false-positive-elimination\" aria-hidden=\"true\" tabindex=\"-1\">Evidence Extraction and False Positive Elimination</a></h2>\n<p>To safely determine if the <code>getattr()</code> use is benign:</p>\n<ol>\n<li>Examine the specific parameters passed to <code>getattr()</code></li>\n<li>Verify the source and context of attribute access</li>\n<li>Confirm the object and attribute namespaces are controlled and trusted</li>\n<li>Validate that the retrieved attributes are limited to expected, safe operations</li>\n</ol>\n<p>JFrog conducts a detailed parameter analysis to determine whether <code>getattr()</code> is used maliciously, by:</p>\n<ul>\n<li>Confirming the exact attributes being accessed</li>\n<li>Verifying no unexpected or dangerous method calls are used</li>\n<li>Ruling out potential arbitrary code execution scenarios</li>\n<li>Classifying the <code>getattr()</code> usage as safe if it meets the above safety criteria</li>\n</ul>\n<p>This systematic approach transforms an initial flag from a potential security concern to a validated safe operation through careful, contextual examination.</p>\n<h2 id=\"additional-information\"><a href=\"#additional-information\" aria-hidden=\"true\" tabindex=\"-1\">Additional Information</a></h2>\n<p><a href=\"https://discuss.pytorch.org/t/securely-serializing-loading-untrusted-pytorch-models/119744\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://discuss.pytorch.org/t/securely-serializing-loading-untrusted-pytorch-models/119744</a>\n<a href=\"https://www.rapid7.com/db/modules/exploit/multi/http/torchserver_cve_2023_43654/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.rapid7.com/db/modules/exploit/multi/http/torchserver_cve_2023_43654/</a></p>\n","description":"PyTorch model using getattr maliciously"}},"context":{}}