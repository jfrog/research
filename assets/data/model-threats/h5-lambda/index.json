{"hash":"c921e630d9d6c9d53a35b95644841c86388ed869","data":{"modelThreatsPost":{"title":"H5-LAMBDA","path":"/model-threats/h5-lambda/","content":"<h2 id=\"overview\"><a href=\"#overview\" aria-hidden=\"true\" tabindex=\"-1\">Overview</a></h2>\n<p>A TensorFlow HDF5/H5 model may contain a \"Lambda\" layer, which contains embedded Python code in binary format. <strong>This code may contain malicious instructions</strong> which will be executed when the model is loaded.</p>\n<p>The HDF5/H5 format is a legacy format used by TensorFlow and Keras to store ML models.</p>\n<p><img src=\"/img/hdf5_format.png\"></p>\n<p>Internally, this format contains an embedded JSON section called <code>model_config</code> which specifies the configuration of the ML Model.</p>\n<p>The Model Configuration specifies all the layers of the model, and may specify a <strong>Lambda</strong> layer.</p>\n<p>The Lambda layer specifies custom operations defined by the model author, which are defined simply by a raw Python code object (Python Bytecode).</p>\n<p><img src=\"/img/hdf5_lambda.png\"></p>\n<p><strong>Since arbitrary Python Bytecode can contain any operation, including malicious operations</strong>, loading an untrusted HDF5/H5 Model is considered to be dangerous.</p>\n<h2 id=\"time-of-infection\"><a href=\"#time-of-infection\" aria-hidden=\"true\" tabindex=\"-1\">Time of Infection</a></h2>\n<p><strong>[v] Model Load</strong></p>\n<p>[] Model Query</p>\n<p>[] Other</p>\n<h2 id=\"evidence-extraction-and-false-positive-elimination\"><a href=\"#evidence-extraction-and-false-positive-elimination\" aria-hidden=\"true\" tabindex=\"-1\">Evidence Extraction and False Positive Elimination</a></h2>\n<p>To safely determine if the suspected HDF5 model contains malicious code -</p>\n<ol>\n<li>Parse the <code>model_config</code> JSON embedded in the HDF5 model to identify <code>Lambda</code> layers</li>\n<li>Extract and decode the Base64-encoded data of the <code>Lambda</code> layer to obtain a Python code object</li>\n<li>Decompile the raw Python code object, ex. using <a href=\"https://github.com/zrax/pycdc\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">pycdc</a></li>\n<li>Examine the decompiled Python code to determine if it contains any malicious instructions</li>\n</ol>\n<p>JFrog conducts extraction, decompilation and detailed analysis on each TensorFlow HDF5 model in order to determine whether any malicious code is present.</p>\n<h2 id=\"additional-information\"><a href=\"#additional-information\" aria-hidden=\"true\" tabindex=\"-1\">Additional Information</a></h2>\n<ul>\n<li><a href=\"https://hiddenlayer.com/innovation-hub/models-are-code/#Code-Execution-via-Lambda\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://hiddenlayer.com/innovation-hub/models-are-code/#Code-Execution-via-Lambda</a></li>\n</ul>\n","description":"TensorFlow H5 model with Lambda Layers containing malicious code"}},"context":{}}