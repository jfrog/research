{"hash":"6925e7cc98205764ba2e182b767a4d088a4a5ef9","data":{"modelThreatsPost":{"title":"TFLOW-MALOPS","path":"/model-threats/tflow-malops/","content":"<h2 id=\"overview\"><a href=\"#overview\" aria-hidden=\"true\" tabindex=\"-1\">Overview</a></h2>\n<p>A TensorFlow SavedModel may contain ReadFile and WriteFile operations, which may lead to <strong>data exfiltration and arbitrary file overwrite</strong> when the model is loaded.</p>\n<p>The TensorFlow SavedModel format is a legacy format used by TensorFlow to store ML models. A SavedModel is a directory that contains a complete TensorFlow program, including weights and computation. It does not require the original model building code to run.</p>\n<p>The SavedModel directory contains the TensorFlow program in a file called <code>saved_model.pb</code>, this is a <a href=\"https://protobuf.dev/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ProtoBuf</a>-serialized binary which contains the TensorFlow \"computation graph\".</p>\n<p><img src=\"/img/savedmodel_format_malops.png\"></p>\n<p>The computation graph specifies which operators to run on which variables.</p>\n<p><img src=\"/img/tensorflow_graph.png\"></p>\n<p>Two of the operators supported by TensorFlow are <a href=\"https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/read-file\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ReadFile</a> and <a href=\"https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/write-file\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">WriteFile</a>, these operators are dangerous since they allow the model to interact with the underlying filesystem of the machine that loads the model.</p>\n<p>For example, using <code>ReadFile</code> - a model would be able to read the machine's users file -</p>\n<pre><code>class MaliciousReader(tf.Module):\n  @tf.function\n  def __call__(self, input):\n    return tf.io.read_file(\"../../../../etc/passwd\")\n</code></pre>\n<p>An even more severe example is a model that would rewrite a critical system file, such as SSH <code>authorized_keys</code>, allowing complete control of the machine by the attackers that injected their SSH key -</p>\n<pre><code>class MaliciousWriter(tf.Module):\n  @tf.function\n  def __call__(self, input):\n    data_to_write = tf.io.decode_base64(\"ZWNobyBwd25k\")\n    tf.io.write_file(\"../../../../home/myuser/.ssh/authorized_keys\", data_to_write)\n    return input + 2\n</code></pre>\n<p><strong>Since the computation graph may include these malicious read/write operators</strong>, loading an untrusted TensorFlow SavedModel is considered to be dangerous.</p>\n<h2 id=\"time-of-infection\"><a href=\"#time-of-infection\" aria-hidden=\"true\" tabindex=\"-1\">Time of Infection</a></h2>\n<p><strong>[v] Model Load</strong></p>\n<p>[] Model Query</p>\n<p>[] Other</p>\n<h2 id=\"evidence-extraction-and-false-positive-elimination\"><a href=\"#evidence-extraction-and-false-positive-elimination\" aria-hidden=\"true\" tabindex=\"-1\">Evidence Extraction and False Positive Elimination</a></h2>\n<p>To safely determine if the suspected TensorFlow SavedModel contains malicious code -</p>\n<ol>\n<li>Identify the <code>saved_model.pb</code> file in your SavedModel directory</li>\n<li>\n<p>Load <code>saved_model.pb</code> and print any <code>ReadFile</code> and <code>WriteFile</code> operators along with their inputs -</p>\n<pre><code class=\"language-python\">import tensorflow as tf\n\nSAVEDMODEL_PATH = \"/path/to/saved_model.pb\"\n\nloaded_model = tf.saved_model.load(SAVEDMODEL_PATH)\nfor func in loaded_model.signatures.values():\n    # Iterate over all operations in the graph\n    for op in func.graph.get_operations():\n        if op.type == 'ReadFile' or op.type == 'WriteFile':\n            args = [input_tensor.name for input_tensor in op.inputs]\n            print(f\"{op.name} {read_file_args}\")\n</code></pre>\n</li>\n<li>Examine the input filepaths to <code>ReadFile</code> and <code>WriteFile</code> to determine whether these operations are malicious</li>\n</ol>\n<p>Note that many <strong>legitimate</strong> ML libraries use <code>ReadFile</code> and <code>WriteFile</code> in a legitimate manner, therefore it is imperative to evaluate the arguments to these operators before deciding whether the model is malicious.</p>\n<p>For example - many ML models use <code>ReadFile</code> with a user-supplied path (ex. <code>arg0_0</code>) in order to read input data for the model from the disk.</p>\n<p><img src=\"/img/legitimate_ops.png\"></p>\n<p>JFrog conducts extraction, decompilation and detailed analysis on each TensorFlow SavedModel, including evaluation of the arguments to <code>ReadFile</code> and <code>WriteFile</code>, in order to determine whether any malicious code is present.</p>\n<h2 id=\"additional-information\"><a href=\"#additional-information\" aria-hidden=\"true\" tabindex=\"-1\">Additional Information</a></h2>\n<ul>\n<li><a href=\"https://hiddenlayer.com/innovation-hub/models-are-code/#Exfiltration-via-ReadFile\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://hiddenlayer.com/innovation-hub/models-are-code/#Exfiltration-via-ReadFile</a></li>\n</ul>\n","description":"TensorFlow SavedModel with malicious operators"}},"context":{}}